# Plot Grid Search and Random Search results side by side with equally sized dots
ggplot(search_results, aes(x = param1, y = param2, color = score)) +
geom_point(size = 3, alpha = 0.8) +  # Use fixed size for all points
facet_wrap(~ method) +               # Facet by method
scale_color_gradient(low = "royalblue", high = "firebrick") +  # Color gradient by score
labs(
x = "Hyperparameter 1",
y = "Hyperparameter 2",
color = "Performance"
) +
theme_minimal() +
theme(
legend.position = "none",
text = element_text(size = 14),
axis.ticks = element_blank(),             # Remove axis ticks
panel.grid = element_blank(),            # Remove grid lines
axis.title = element_text(size = 16),    # Keep axis labels
axis.text = element_blank()
)
library(ggplot2)
# Load necessary libraries
library(MASS)
library(ggplot2)
# Generate synthetic dataset
set.seed(123)
n <- 150
class1 <- data.frame(x1 = rnorm(n, mean = 2, sd = 1),
x2 = rnorm(n, mean = 3, sd = 1),
class = "Class1")
class2 <- data.frame(x1 = rnorm(n, mean = 5, sd = 1),
x2 = rnorm(n, mean = 1, sd = 1),
class = "Class2")
class3 <- data.frame(x1 = rnorm(n, mean = 3, sd = 1),
x2 = rnorm(n, mean = 6, sd = 1),
class = "Class3")
data <- rbind(class1, class2, class3)
# Perform LDA
lda_model <- lda(class ~ x1 + x2, data = data)
lda_predictions <- predict(lda_model)
# Add LDA results to the data
data$LD1 <- lda_predictions$x[, 1]
data$LD2 <- lda_predictions$x[, 2]
# Plot the LDA results
ggplot(data, aes(x = LD1, y = LD2, color = class)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "LDA Results: Separation of Classes",
x = "Linear Discriminant 1 (LD1)",
y = "Linear Discriminant 2 (LD2)") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12)
)
# Load necessary libraries
library(MASS)
library(ggplot2)
# Generate synthetic dataset
set.seed(123)
n <- 150
class1 <- data.frame(x1 = rnorm(n, mean = 2, sd = 1),
x2 = rnorm(n, mean = 3, sd = 1),
class = "Class1")
class2 <- data.frame(x1 = rnorm(n, mean = 5, sd = 1),
x2 = rnorm(n, mean = 1, sd = 1),
class = "Class2")
class3 <- data.frame(x1 = rnorm(n, mean = 3, sd = 1),
x2 = rnorm(n, mean = 6, sd = 1),
class = "Class3")
data <- rbind(class1, class2, class3)
# Perform LDA
lda_model <- lda(class ~ x1 + x2, data = data)
lda_predictions <- predict(lda_model)
# Add LDA results to the data
data$LD1 <- lda_predictions$x[, 1]
data$LD2 <- lda_predictions$x[, 2]
# Create a grid of LD1 and LD2 values to plot decision boundaries
grid <- expand.grid(
LD1 = seq(min(data$LD1) - 1, max(data$LD1) + 1, length = 200),
LD2 = seq(min(data$LD2) - 1, max(data$LD2) + 1, length = 200)
)
# Predict class probabilities for the grid
grid_pred <- predict(lda_model, newdata = data.frame(x1 = grid$LD1, x2 = grid$LD2))
# Add the predicted class to the grid
grid$class <- grid_pred$class
# Plot the LDA results with decision boundaries
ggplot() +
# Plot decision boundaries
geom_tile(data = grid, aes(x = LD1, y = LD2, fill = class), alpha = 0.3) +
# Plot the data points
geom_point(data = data, aes(x = LD1, y = LD2, color = class), size = 3, alpha = 0.7) +
labs(title = "LDA Results with Decision Boundaries",
x = "Linear Discriminant 1 (LD1)",
y = "Linear Discriminant 2 (LD2)") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12)
) +
scale_fill_manual(values = c("Class1" = "lightblue", "Class2" = "lightgreen", "Class3" = "lightpink")) +
scale_color_manual(values = c("Class1" = "blue", "Class2" = "green", "Class3" = "red"))
### QDA
# Load necessary libraries
library(MASS)
library(ggplot2)
library(gridExtra)
# Generate synthetic dataset
set.seed(123)
n <- 150
class1 <- data.frame(x1 = rnorm(n, mean = 2, sd = 1),
x2 = rnorm(n, mean = 3, sd = 1),
class = "Class1")
class2 <- data.frame(x1 = rnorm(n, mean = 5, sd = 1),
x2 = rnorm(n, mean = 1, sd = 1),
class = "Class2")
class3 <- data.frame(x1 = rnorm(n, mean = 3, sd = 1),
x2 = rnorm(n, mean = 6, sd = 1),
class = "Class3")
data <- rbind(class1, class2, class3)
# Perform LDA
lda_model <- lda(class ~ x1 + x2, data = data)
lda_predictions <- predict(lda_model)
# Perform QDA
qda_model <- qda(class ~ x1 + x2, data = data)
qda_predictions <- predict(qda_model)
# Create a grid of x1 and x2 values to plot decision boundaries
grid <- expand.grid(
x1 = seq(min(data$x1) - 1, max(data$x1) + 1, length = 200),
x2 = seq(min(data$x2) - 1, max(data$x2) + 1, length = 200)
)
# Predict class for the grid using LDA
grid_lda <- grid
grid_lda$class <- predict(lda_model, newdata = grid)$class
# Predict class for the grid using QDA
grid_qda <- grid
grid_qda$class <- predict(qda_model, newdata = grid)$class
# Plot LDA results
plot_lda <- ggplot() +
geom_tile(data = grid_lda, aes(x = x1, y = x2, fill = class), alpha = 0.3) +
geom_point(data = data, aes(x = x1, y = x2, color = class), size = 3, alpha = 0.7) +
labs(title = "LDA Decision Boundaries",
x = "x1", y = "x2") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12)
) +
scale_fill_manual(values = c("Class1" = "lightblue", "Class2" = "lightgreen", "Class3" = "lightpink")) +
scale_color_manual(values = c("Class1" = "blue", "Class2" = "green", "Class3" = "red"))
# Plot QDA results
plot_qda <- ggplot() +
geom_tile(data = grid_qda, aes(x = x1, y = x2, fill = class), alpha = 0.3) +
geom_point(data = data, aes(x = x1, y = x2, color = class), size = 3, alpha = 0.7) +
labs(title = "QDA Decision Boundaries",
x = "x1", y = "x2") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12)
) +
scale_fill_manual(values = c("Class1" = "lightblue", "Class2" = "lightgreen", "Class3" = "lightpink")) +
scale_color_manual(values = c("Class1" = "blue", "Class2" = "green", "Class3" = "red"))
# Arrange the plots side by side
grid.arrange(plot_lda, plot_qda, ncol = 2)
# reproduce example in ISLR2
mu1 <- -1.25
mu2 <- 1.25
sigma1 <- 1
sigma2 <- 1
# reproduce example in ISLR2
mu1 <- -1.5
mu2 <- 1.5
sigma1 <- 1
sigma2 <- 1
bayes_boundary <- (mu1 + mu2) / 2
p1 <- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5, color = td_colors$nice$emerald) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5, color = td_colors$nice$opera_mauve) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) +
remove_axis("y")
set.seed(42)
d <- tribble(
~class, ~x,
1, rnorm(20, mean = mu1, sd = sigma1),
2, rnorm(20, mean = mu2, sd = sigma2)
) %>%
unnest(x)
lda_boundary <-
(mean(filter(d, class == 1)$x) + mean(filter(d, class == 2)$x)) / 2
p2 <- d %>%
ggplot(aes(x, fill = factor(class), color = factor(class))) +
geom_histogram(bins = 13, alpha = 0.5, position = "identity") +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) +
geom_vline(xintercept = lda_boundary, lty = 1, size = 1.5) +
scale_fill_manual(values = c(td_colors$nice$emerald,
td_colors$nice$opera_mauve)) +
scale_color_manual(values = c(td_colors$nice$emerald,
td_colors$nice$opera_mauve)) +
theme(legend.position = "none")
p1 | p2
library(tidyverse)
library(broom)
library(gt)
install.packages("gt")
library(gt)
library(patchwork) # for composing plots
library(tictoc) # for timing code execution
install.packages("tictoc")
library(tictoc) # for timing code execution
# Load my R package and set the ggplot theme
library(dunnr)
install.packages("dunnr")
# Load my R package and set the ggplot theme
library(dunnr)
# reproduce example in ISLR2
mu1 <- -1.5
mu2 <- 1.5
sigma1 <- 1
sigma2 <- 1
bayes_boundary <- (mu1 + mu2) / 2
p1 <- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5, color = td_colors$nice$emerald) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5, color = td_colors$nice$opera_mauve) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) +
remove_axis("y")
# Load my R package and set the ggplot theme
library(dunnr)
extrafont::loadfonts(device = "win", quiet = TRUE)
extrafont::loadfonts(device = "os", quiet = TRUE)
theme_set(theme_td())
set_geom_fonts()
set_palette()
p1 <- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) +
remove_axis("y")
p1 <- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) +
remove_axis("y")
ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5)
p1 <- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1),
geom = "line", size = 1.5) +
stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2),
geom = "line", size = 1.5) +
geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5)+
theme_minimal() +
theme(
legend.position = "none",
text = element_text(size = 14),
axis.ticks = element_blank(),             # Remove axis ticks
panel.grid = element_blank(),            # Remove grid lines
axis.title = element_text(size = 16),    # Keep axis labels
axis.text = element_blank()
)
p1
(-1.5) + (1.5/2) + log(0.5)
# Data for probability distribution
outcomes <- 0:3
probabilities <- dbinom(outcomes, size = 3, prob = 0.5)
# Data for cumulative distribution
cumulative_probabilities <- pbinom(outcomes, size = 3, prob = 0.5)
# Combine data into a data frame
data <- data.frame(
Outcomes = outcomes,
Probabilities = probabilities,
Cumulative = cumulative_probabilities
)
# Load ggplot2
library(ggplot2)
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
# Plot Cumulative Probability Distribution
plot_cumulative <- ggplot(data, aes(x = Outcomes, y = Cumulative)) +
geom_step(color = "blue", size = 1.2) +
geom_point(size = 3, color = "blue") +
labs(
title = "Cumulative Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Cumulative Probability"
) +
theme_minimal()
# Print the plots
library(gridExtra)
# Plot Cumulative Probability Distribution
plot_cumulative <- ggplot(data, aes(x = Outcomes, y = Cumulative)) +
geom_step(color = "blue", linewidth = 1.2) +
geom_point(size = 3, color = "blue") +
labs(
title = "Cumulative Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Cumulative Probability"
) +
theme_minimal()
plot_prob
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_hist(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
plot_cumulative
# Plot Probability Distribution as a Histogram
plot_prob_hist <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_histogram(stat = "identity", fill = "skyblue", color = "black", binwidth = 1) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
plot_prob_hist
# Plot Probability Distribution as a Histogram
plot_prob_hist <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_histogram(stat = "identity", fill = "skyblue",
color = "black") +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
plot_prob
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_bar(stat = "identity", fill = "steelblue", color = "black", width = 0.6) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
plot_prob
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_bar(stat = "identity", fill = "lightblue", color = "black", width = 0.6) +
labs(
title = "Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Probability"
) +
theme_minimal()
plot_prob
# Plot Cumulative Probability Distribution
plot_cumulative <- ggplot(data, aes(x = Outcomes, y = Cumulative)) +
geom_step(color = "lightblue", linewidth = 1.2) +
geom_point(size = 3, color = "lightblue") +
labs(
title = "Cumulative Probability Distribution for Tossing a Coin 3 Times",
x = "Number of Heads",
y = "Cumulative Probability"
) +
theme_minimal()
plot_cumulative
# Print the plots
library(gridExtra)
grid.arrange(plot_prob, plot_cumulative, ncol = 2)
# Plot Cumulative Probability Distribution
plot_cumulative <- ggplot(data, aes(x = Outcomes, y = Cumulative)) +
geom_step(color = "lightblue", linewidth = 1.2) +
geom_point(size = 3, color = "lightblue") +
labs(
x = "x",
y = expression(P(X <= x))
) +
theme_minimal()
plot_cumulative
# Plot Probability Distribution
plot_prob <- ggplot(data, aes(x = Outcomes, y = Probabilities)) +
geom_bar(stat = "identity", fill = "lightblue", color = "black", width = 0.6) +
labs(,
x = "X",
y = expression(P(X = x))
) +
theme_minimal()
plot_prob
install.packages("ROCR")
install_torch()
install_torch()
library(torch)
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
library(ggplot2)
torch_manual_seed(13)
library(lantern)
library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
library(ggplot2)
torch_manual_seed(13)
install_torch()
library(ISLR2)
Gitters <- na.omit(Hitters)
n <- nrow(Gitters)
set.seed(13)
ntest <- trunc(n / 3)
testid <- sample(1:n, ntest)
lfit <- lm(Salary ~ ., data = Gitters[-testid, ])
lpred <- predict(lfit, Gitters[testid, ])
with(Gitters[testid, ], mean(abs(lpred - Salary)))
x <- scale(model.matrix(Salary ~ . - 1, data = Gitters))
y <- Gitters$Salary
library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
library(ggplot2)
torch_manual_seed(13)
install_torch()
install_torch()
library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
library(ggplot2)
torch_manual_seed(13)
modnn <- nn_module(
initialize = function(input_size) {
self$hidden <- nn_linear(input_size, 50)
self$activation <- nn_relu()
self$dropout <- nn_dropout(0.4)
self$output <- nn_linear(50, 1)
},
forward = function(x) {
x %>%
self$hidden() %>%
self$activation() %>%
self$dropout() %>%
self$output()
}
)
modnn <- modnn %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_mae())
) %>%
set_hparams(input_size = ncol(x))
fitted <- modnn %>%
fit(
data = list(x[-testid, ], matrix(y[-testid], ncol = 1)),
valid_data = list(x[testid, ], matrix(y[testid], ncol = 1)),
epochs = 30 # 50
)
install.packages("jsonlite")
library(jsonlite)
library(ggplot2)
library(tidyverse)
library(dbscan)
library(mclust)
library(randomForest)
setwd("~/Dropbox/ts/uni_konstanz/2023/teaching/statistical-learning/wise-24-25/course-material/practicals/13-pca")
library(readr)
penguins = read_csv("penguins.csv", col_names = T)
head(penguins)
tail(penguins)
dim(penguins)
df <- na.omit(penguins)
dim(df)
reduced_df <-  cbind(df$bill_length_mm, df$bill_depth_mm, df$flipper_length_mm, df$body_mass_g, df$species)
colnames(reduced_df) <- c("bill_L", "bill_D", "flipper", "body", "species")
library(tidyverse)
library(ggfortify)
pca_values <-  prcomp(reduced_df, center = TRUE, scale = TRUE)
reduced_df
