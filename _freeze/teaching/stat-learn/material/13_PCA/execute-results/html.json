{
  "hash": "a6dbf6b60d630817b5386603bf9c1233",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical Learning Lab 13 - PCA\"\neditor: visual\nformat:\n  html:\n    embed-resources: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(mclust)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nPackage 'mclust' version 6.1.1\nType 'citation(\"mclust\")' for citing this R package in publications.\n\nAttaching package: 'mclust'\n\nThe following object is masked from 'package:purrr':\n\n    map\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(randomForest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrandomForest 4.7-1.2\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: 'randomForest'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n```\n\n\n:::\n:::\n\n\n## Redux - Young People Survey:\n\nBelow we find survey data of 1000 people in Slovakia aged 15 to 30. We will try to detect distinct features using PCA\n\nFirst we load the dataset and this time we transform categorical data to binary dummies for each level.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresponses = read.csv('responses.csv')\ndf_youth = data.frame(model.matrix(~ . -1, data = responses))\ndf_youth_scaled = data.frame(scale(df_youth))\n```\n:::\n\n\n\n\n### PCA\n\nWe will continue with last weeks data by applying PCA to find some better way to visualize our data. \n\nLast time we clustered our data and then went on to visualize this clustering. Unfortunately we did not scale our data and thus we overvalued the contributions of the height and weight variables. In PCA this has similar repercussions as we can see by setting the scale argument.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npr_out = prcomp(df_youth, scale=TRUE)\npr_out_unscaled = prcomp(df_youth, scale=FALSE)\n\nl = length(pr_out$sdev)\npca_plot_big = data.frame(\n  var_unscaled = pr_out_unscaled$sdev ^ 2 / sum(pr_out_unscaled$sdev ^ 2),\n  var_scaled = pr_out$sdev ^ 2 / sum(pr_out$sdev ^ 2),\n  PC = c(1:l))\n                          \npca_plot_big %>%\n  ggplot(aes(x = PC, y = var_unscaled, alpha = 0.8)) + geom_bar(stat=\"identity\") \n```\n\n::: {.cell-output-display}\n![](13_PCA_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\npca_plot_big %>%\n  ggplot(aes(x = PC, y = var_scaled, alpha = 0.8)) + geom_bar(stat=\"identity\") \n```\n\n::: {.cell-output-display}\n![](13_PCA_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n\nAs we see here, the unscaled version is dominated by one factor which is a combination of age/weight/height, while the scaled result shows a much flatter distribution of relevant features. By looking at the explained variance of each PC, we can see how much redundant information is in our data. This is once again an exercise in \"feeling things out\" - we want to keep as much information as possible for using as little variables as possible.\nWe could use the summary function but it is very unhandy with a large number of dimensions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# summary(pr_out)\n```\n:::\n\n\n\n\n\nFor demonstration purposes we are going to look at the unscaled version. \n \n \nBy default, the prcomp() function centers the variables to have mean zero. By using the option scale = TRUE, we scale the variables to have standard deviation one. The output from prcomp() contains a number of useful quantities.\n\n\n\n- rotation stores the factor loadings for each variable\n\n- x stores the PC score vectors\n\n- sdev stores the sd of each PC\n\n\nWe can use these to better visualize our previous results. Let's cluster the data by PC dimensions instead of \"natural ones\".\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_pr = data.frame(pr_out_unscaled$x[, 1:20])\nhc.complete = hclust(dist(df_pr), method=\"complete\")\nplot(hc.complete, hang=-1, ann=F, labels = F)\n```\n\n::: {.cell-output-display}\n![](13_PCA_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_pr$cluster = factor(cutree(hc.complete, 4))\ndf_pr %>%\n  ggplot(aes(x = PC1, y = PC2, color = cluster)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](13_PCA_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nAs we can see, now our clusters are clearly seperable across the first two PC dimensions. But we cannot really get substantive meaning out of this. Checking factor loadings can make things a bit clearer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_k_loadings = function(pr_obj, PCnum, k) {\n  loadings = data.frame(pr_obj$rotation)\n  loadings$Variable = rownames(loadings)\n  \n  topPC = loadings[order(abs(loadings[[PCnum]]),\n                         decreasing = TRUE), ][1:k, ]\n  \n  print(topPC[PCnum])\n}\n\ntop_k_loadings(pr_out_unscaled, 1, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       PC1\nWeight          0.84693078\nHeight          0.51068802\nLife.struggles -0.03775814\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out_unscaled, 2, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               PC2\nHeight  0.82966634\nWeight -0.51998010\nAge    -0.06642844\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out_unscaled, 3, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      PC3\nAge             0.2917059\nArt.exhibitions 0.2029329\nClassical.music 0.1974964\n```\n\n\n:::\n:::\n\n\n\nAs we can see the unscaled variables clearly dominate the first two PCs. Once we redo this for the correctly scaled data we can find some new info:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_k_loadings(pr_out, 1, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    PC1\nGenderfemale -0.2500374\nGendermale    0.2496470\nHeight        0.2029337\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out, 2, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       PC2\nClassical.music -0.1707829\nOpera           -0.1690747\nSwing..Jazz     -0.1686890\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out, 3, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        PC3\nSpending.on.looks 0.2225731\nHiphop..Rap       0.1950597\nShopping          0.1948451\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out, 4, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                          PC4\nAlternative        -0.2068746\nAlcoholdrink.a.lot -0.1890481\nRock               -0.1777432\n```\n\n\n:::\n\n```{.r .cell-code}\ntop_k_loadings(pr_out, 5, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         PC5\nLoneliness        -0.1858763\nHealth            -0.1795914\nChanging.the.past -0.1758840\n```\n\n\n:::\n:::\n\n\n\nLooks like (apart from PC1 for Gender), we get PC dimensions mostly along subcultural lines!\nWhen we run a clustering algorithm, we see that the subgroups seem to be pretty visible across the \"classical\" and \"hiphop\" PC dimensions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_pr_scaled = data.frame(pr_out$x[, 2:4])\nhc.complete_scaled = hclust(dist(df_pr_scaled), method=\"complete\")\ndf_pr_scaled$cluster = factor(cutree(hc.complete_scaled, 3))\ndf_pr_scaled %>%\n  ggplot(aes(x = PC2, y = PC3, color = cluster)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](13_PCA_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "13_PCA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}