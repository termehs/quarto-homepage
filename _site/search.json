[
  {
    "objectID": "rpackage/index.html",
    "href": "rpackage/index.html",
    "title": "R packages",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nData Wrangling and Visualization with Tidyverse\n\n\nMSc course\n\n\n\n\nFallacies of Inferential Statistics\n\n\nMSc seminar\n\n\n\n\nStatistical Analysis of Social Networks\n\n\nMSc course\n\n\n\n\nStatistical Learning\n\n\nMSc course\n\n\n\n\nStatistics\n\n\nBSc course\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html",
    "href": "teaching/Tidyverse/material/college-majors.html",
    "title": "What should I major in?",
    "section": "",
    "text": "The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#packages",
    "href": "teaching/Tidyverse/material/college-majors.html#packages",
    "title": "What should I major in?",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the scales package for better formatting of labels on visualisations, and the data lives in the fivethirtyeight package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#data",
    "href": "teaching/Tidyverse/material/college-majors.html#data",
    "title": "What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found in the fivethirtyeight package, and it’s called college_recent_grads. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?college_recent_grads in the Console or using the Help menu in RStudio to search for college_recent_grads. You can also find this information here.\nYou can also take a quick peek at your data frame and view its dimensions with the glimpse function.\n\nglimpse(college_recent_grads)\n\nRows: 173\nColumns: 21\n$ rank                        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…\n$ major_code                  &lt;int&gt; 2419, 2416, 2415, 2417, 2405, 2418, 6202, …\n$ major                       &lt;chr&gt; \"Petroleum Engineering\", \"Mining And Miner…\n$ major_category              &lt;chr&gt; \"Engineering\", \"Engineering\", \"Engineering…\n$ total                       &lt;int&gt; 2339, 756, 856, 1258, 32260, 2573, 3777, 1…\n$ sample_size                 &lt;int&gt; 36, 7, 3, 16, 289, 17, 51, 10, 1029, 631, …\n$ men                         &lt;int&gt; 2057, 679, 725, 1123, 21239, 2200, 2110, 8…\n$ women                       &lt;int&gt; 282, 77, 131, 135, 11021, 373, 1667, 960, …\n$ sharewomen                  &lt;dbl&gt; 0.1205643, 0.1018519, 0.1530374, 0.1073132…\n$ employed                    &lt;int&gt; 1976, 640, 648, 758, 25694, 1857, 2912, 15…\n$ employed_fulltime           &lt;int&gt; 1849, 556, 558, 1069, 23170, 2038, 2924, 1…\n$ employed_parttime           &lt;int&gt; 270, 170, 133, 150, 5180, 264, 296, 553, 1…\n$ employed_fulltime_yearround &lt;int&gt; 1207, 388, 340, 692, 16697, 1449, 2482, 82…\n$ unemployed                  &lt;int&gt; 37, 85, 16, 40, 1672, 400, 308, 33, 4650, …\n$ unemployment_rate           &lt;dbl&gt; 0.018380527, 0.117241379, 0.024096386, 0.0…\n$ p25th                       &lt;dbl&gt; 95000, 55000, 50000, 43000, 50000, 50000, …\n$ median                      &lt;dbl&gt; 110000, 75000, 73000, 70000, 65000, 65000,…\n$ p75th                       &lt;dbl&gt; 125000, 90000, 105000, 80000, 75000, 10200…\n$ college_jobs                &lt;int&gt; 1534, 350, 456, 529, 18314, 1142, 1768, 97…\n$ non_college_jobs            &lt;int&gt; 364, 257, 176, 102, 4440, 657, 314, 500, 1…\n$ low_wage_jobs               &lt;int&gt; 193, 50, 0, 0, 972, 244, 259, 220, 3253, 3…\n\n\nThe college_recent_grads data frame is a trove of information. Let’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "teaching/Tidyverse/material/college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here – we’re interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate)\n\n# A tibble: 173 × 21\n    rank major_code major           major_category total sample_size   men women\n   &lt;int&gt;      &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;int&gt;       &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    53       4005 Mathematics An… Computers & M…   609           7   500   109\n 2    74       3801 Military Techn… Industrial Ar…   124           4   124     0\n 3    84       3602 Botany          Biology & Lif…  1329           9   626   703\n 4   113       1106 Soil Science    Agriculture &…   685           4   476   209\n 5   121       2301 Educational Ad… Education        804           5   280   524\n 6    15       2409 Engineering Me… Engineering     4321          30  3526   795\n 7    20       3201 Court Reporting Law & Public …  1148          14   877   271\n 8   120       2305 Mathematics Te… Education      14237         123  3872 10365\n 9     1       2419 Petroleum Engi… Engineering     2339          36  2057   282\n10    65       1100 General Agricu… Agriculture &… 10399         158  6053  4346\n# ℹ 163 more rows\n# ℹ 13 more variables: sharewomen &lt;dbl&gt;, employed &lt;int&gt;,\n#   employed_fulltime &lt;int&gt;, employed_parttime &lt;int&gt;,\n#   employed_fulltime_yearround &lt;int&gt;, unemployed &lt;int&gt;,\n#   unemployment_rate &lt;dbl&gt;, p25th &lt;dbl&gt;, median &lt;dbl&gt;, p75th &lt;dbl&gt;,\n#   college_jobs &lt;int&gt;, non_college_jobs &lt;int&gt;, low_wage_jobs &lt;int&gt;\n\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g. major_code, major_category) and some we might want front and center are not easily viewed (e.g. unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate) %&gt;%\n  select(rank, major, unemployment_rate)\n\n# A tibble: 173 × 3\n    rank major                                      unemployment_rate\n   &lt;int&gt; &lt;chr&gt;                                                  &lt;dbl&gt;\n 1    53 Mathematics And Computer Science                     0      \n 2    74 Military Technologies                                0      \n 3    84 Botany                                               0      \n 4   113 Soil Science                                         0      \n 5   121 Educational Administration And Supervision           0      \n 6    15 Engineering Mechanics Physics And Science            0.00633\n 7    20 Court Reporting                                      0.0117 \n 8   120 Mathematics Teacher Education                        0.0162 \n 9     1 Petroleum Engineering                                0.0184 \n10    65 General Agriculture                                  0.0196 \n# ℹ 163 more rows\n\n\nOk, this is looking better, but do we really need to display all those decimal places in the unemployment variable? Not really!\nWe can use the percent() function to clean up the display a bit.\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate) %&gt;%\n  select(rank, major, unemployment_rate) %&gt;%\n  mutate(unemployment_rate = percent(unemployment_rate))\n\n# A tibble: 173 × 3\n    rank major                                      unemployment_rate\n   &lt;int&gt; &lt;chr&gt;                                      &lt;chr&gt;            \n 1    53 Mathematics And Computer Science           0.00000%         \n 2    74 Military Technologies                      0.00000%         \n 3    84 Botany                                     0.00000%         \n 4   113 Soil Science                               0.00000%         \n 5   121 Educational Administration And Supervision 0.00000%         \n 6    15 Engineering Mechanics Physics And Science  0.63343%         \n 7    20 Court Reporting                            1.16897%         \n 8   120 Mathematics Teacher Education              1.62028%         \n 9     1 Petroleum Engineering                      1.83805%         \n10    65 General Agriculture                        1.96425%         \n# ℹ 163 more rows"
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "teaching/Tidyverse/material/college-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nThe `desc` function specifies that we want `unemployment_rate` in descending order.\n\n\ncollege_recent_grads %&gt;%\n  arrange(desc(unemployment_rate)) %&gt;%\n  select(rank, major, unemployment_rate)\n\n# A tibble: 173 × 3\n    rank major                                      unemployment_rate\n   &lt;int&gt; &lt;chr&gt;                                                  &lt;dbl&gt;\n 1     6 Nuclear Engineering                                    0.177\n 2    90 Public Administration                                  0.159\n 3    85 Computer Networking And Telecommunications             0.152\n 4   171 Clinical Psychology                                    0.149\n 5    30 Public Policy                                          0.128\n 6   106 Communication Technologies                             0.120\n 7     2 Mining And Mineral Engineering                         0.117\n 8    54 Computer Programming And Data Processing               0.114\n 9    80 Geography                                              0.113\n10    59 Architecture                                           0.113\n# ℹ 163 more rows\n\n\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding top_n(3) at the end of the pipeline."
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "teaching/Tidyverse/material/college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\nNote: A percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: Wikipedia\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot() function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram – or more accurately, the binwidth we didn’t specify. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads %&gt;%\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n# A tibble: 1 × 7\n    min    max   mean   med     sd    q1    q3\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 22000 110000 40151. 36000 11470. 33000 45000\n\n\n\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\n\ncollege_recent_grads %&gt;%\n  group_by(major_category) %&gt;%\n  summarise(___ = ___(median)) %&gt;%\n  arrange(___)\n\n\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\n\ncollege_recent_grads %&gt;%\n  count(major_category)\n\n# A tibble: 16 × 2\n   major_category                          n\n   &lt;chr&gt;                               &lt;int&gt;\n 1 Agriculture & Natural Resources        10\n 2 Arts                                    8\n 3 Biology & Life Science                 14\n 4 Business                               13\n 5 Communications & Journalism             4\n 6 Computers & Mathematics                11\n 7 Education                              16\n 8 Engineering                            29\n 9 Health                                 12\n10 Humanities & Liberal Arts              15\n11 Industrial Arts & Consumer Services     7\n12 Interdisciplinary                       1\n13 Law & Public Policy                     5\n14 Physical Sciences                      10\n15 Psychology & Social Work                9\n16 Social Science                          9"
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#all-stem-fields-arent-the-same",
    "href": "teaching/Tidyverse/material/college-majors.html#all-stem-fields-arent-the-same",
    "title": "What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories &lt;- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads &lt;- college_recent_grads %&gt;%\n  mutate(major_type = ifelse(major_category %in% stem_categories, \"stem\", \"not stem\"))\n\nLet’s unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx &lt; y\nless than\n\n\nx &gt; y\ngreater than\n\n\nx &lt;= y\nless than or equal to\n\n\nx &gt;= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads %&gt;%\n  filter(\n    major_type == \"stem\",\n    median &lt; 36000\n  )\n\n# A tibble: 10 × 22\n    rank major_code major        major_category  total sample_size    men  women\n   &lt;int&gt;      &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;           &lt;int&gt;       &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n 1    93       1301 Environment… Biology & Lif…  25965         225  10787  15178\n 2    98       5098 Multi-Disci… Physical Scie…  62052         427  27015  35037\n 3   102       3608 Physiology   Biology & Lif…  22060          99   8422  13638\n 4   106       2001 Communicati… Computers & M…  18035         208  11431   6604\n 5   109       3611 Neuroscience Biology & Lif…  13663          53   4944   8719\n 6   111       5002 Atmospheric… Physical Scie…   4043          32   2744   1299\n 7   123       3699 Miscellaneo… Biology & Lif…  10706          63   4747   5959\n 8   124       3600 Biology      Biology & Lif… 280709        1370 111762 168947\n 9   133       3604 Ecology      Biology & Lif…   9154          86   3878   5276\n10   169       3609 Zoology      Biology & Lif…   8409          47   3050   5359\n# ℹ 14 more variables: sharewomen &lt;dbl&gt;, employed &lt;int&gt;,\n#   employed_fulltime &lt;int&gt;, employed_parttime &lt;int&gt;,\n#   employed_fulltime_yearround &lt;int&gt;, unemployed &lt;int&gt;,\n#   unemployment_rate &lt;dbl&gt;, p25th &lt;dbl&gt;, median &lt;dbl&gt;, p75th &lt;dbl&gt;,\n#   college_jobs &lt;int&gt;, non_college_jobs &lt;int&gt;, low_wage_jobs &lt;int&gt;,\n#   major_type &lt;chr&gt;\n\n\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top."
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "teaching/Tidyverse/material/college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "teaching/Tidyverse/material/college-majors.html#further-exploration",
    "href": "teaching/Tidyverse/material/college-majors.html#further-exploration",
    "title": "What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s)."
  },
  {
    "objectID": "teaching/Tidyverse/material/la-quinta.html",
    "href": "teaching/Tidyverse/material/la-quinta.html",
    "title": "La Quinta is Spanish for next to Denny’s",
    "section": "",
    "text": "Have you ever taken a road trip in the US and thought to yourself “I wonder what La Quinta means”. Well, the late comedian Mitch Hedberg thinks it’s Spanish for next to Denny’s.\nIf you’re not familiar with these two establishments, Denny’s is a casual diner chain that is open 24 hours and La Quinta Inn and Suites is a hotel chain.\nThese two establishments tend to be clustered together, or at least this observation is a joke made famous by Mitch Hedberg. In this lab we explore the validity of this joke and along the way learn some more data wrangling and tips for visualizing spatial data.\nThe inspiration for this comes from a blog post by John Reiser on his new jersey geographer blog. You can read that analysis here. Reiser’s blog post focuses on scraping data from Denny’s and La Quinta Inn and Suites websites using Python. Here, we focus on visualization and analysis of these data."
  },
  {
    "objectID": "teaching/Tidyverse/material/la-quinta.html#packages",
    "href": "teaching/Tidyverse/material/la-quinta.html#packages",
    "title": "La Quinta is Spanish for next to Denny’s",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "teaching/Tidyverse/material/la-quinta.html#data",
    "href": "teaching/Tidyverse/material/la-quinta.html#data",
    "title": "La Quinta is Spanish for next to Denny’s",
    "section": "Data",
    "text": "Data\nThe data sets we’ll use are called dennys and laquinta and are available for download. Note that these data were scraped from here and here, respectively. You can find information about the data sets here and here. To help with our analysis we will also use a data set on US states.\n\nlaquinta &lt;- read_csv(\"data/laquinta.csv\")\ndennys &lt;- read_csv(\"data/dennys.csv\")\nstates &lt;- read_csv(\"data/states.csv\")\n\nEach observation in the states dataset represents a state, including DC. Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles)."
  },
  {
    "objectID": "teaching/Tidyverse/material/starwars.html",
    "href": "teaching/Tidyverse/material/starwars.html",
    "title": "Visualizing Starwars characters",
    "section": "",
    "text": "Glimpse at the starwars data frame.\n\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\nModify the following plot to change the color of all points to \"pink\".\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"pink\")\n\nWarning: Removed 51 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nAdd labels for title, x and y axes, and size of points. Uncomment to see the effect.\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"#30509C\") +\n  labs(\n    #title = \"___\",\n    #x = \"___\", \n    #y = \"___\",\n    #___\n    )\n\nWarning: Removed 51 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nPick a single numerical variable and make a histogram of it. Select a reasonable binwidth for it.\n\n(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with eval: false because the current code in there is not valid code and hence the document wouldn’t knit. Once you replace the code with valid code, set the chunk option to eval: true, or remove the eval option altogether since it’s set to true by default.)\n\nggplot(starwars, aes(___)) +\n  geom___\n\n\nPick a numerical variable and a categorical variable and make a visualization (you pick the type!) to visualization the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\nInterpretation goes here…\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\nInterpretation goes here…\n\nPick two numerical variables and two categorical variables and make a visualization that incorporates all of them and provide an interpretation with your answer.\n\n(This time no starter code is provided, you’re on your own!)\nInterpretation goes here…"
  },
  {
    "objectID": "teaching/Tidyverse/material/hotels-datawrangling.html",
    "href": "teaching/Tidyverse/material/hotels-datawrangling.html",
    "title": "Hotel bookings - data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\nThe data is also available as a csv file which you can import directly."
  },
  {
    "objectID": "teaching/Tidyverse/material/hotels-datawrangling.html#exercises",
    "href": "teaching/Tidyverse/material/hotels-datawrangling.html#exercises",
    "title": "Hotel bookings - data wrangling",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.\nWarm up! Take a look at an overview of the data with the skim() function.\nNote: I already gave you the answer to this exercise. You just need to knit the document and view the output. A definition of all variables is given in the Data dictionary section at the end, though you don’t need to familiarize yourself with all variables in order to work through these exercises.\n\nskim(hotels)\n\n\nData summary\n\n\nName\nhotels\n\n\nNumber of rows\n119390\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n178\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n334\n0\n\n\ncompany\n0\n1\n1\n4\n0\n353\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nreservation_status\n0\n1\n7\n9\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\n\n\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\n\n\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\n\n\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\n\n\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\n\n\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nExercise 2.\nAre people traveling on a whim? Let’s see…\nFill in the blanks for filtering for hotel bookings where the guest is not from the US (country code \"USA\") and the lead_time is less than 1 day.\n\nhotels %&gt;%\n  filter(\n    country ____ \"USA\", \n    lead_time ____ ____\n    )\n\n\n\nExercise 3.\nHow many bookings involve at least 1 child or baby?\nIn the following chunk, replace\n\n[AT LEAST] with the logical operator for “at least” (in two places)\n[OR] with the logical operator for “or”\n\nNote: You will need to set eval=TRUE when you have an answer you want to try out in the qmd file.\n\nhotels %&gt;%\n  filter(\n    children [AT LEAST] 1 [OR] babies [AT LEAST] 1\n    )\n\n\n\nExercise 4.\nDo you think it’s more likely to find bookings with children or babies in city hotels or resort hotels? Test your intuition. Using filter() determine the number of bookings in resort hotels that have more than 1 child or baby in the room? Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.\n\n# add code here\n# pay attention to correctness and code style\n\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 5.\nCreate a frequency table of the number of adults in a booking. Display the results in descending order so the most common observation is on top. What is the most common number of adults in bookings in this dataset? Are there any surprising results?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 6.\nRepeat Exercise 5, once for canceled bookings (is_canceled coded as 1) and once for not canceled bookings (is_canceled coded as 0). What does this reveal about the surprising results you spotted in the previous exercise?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 7.\nCalculate minimum, mean, median, and maximum average daily rate (adr) grouped by hotel type so that you can get these statistics separately for resort and city hotels. Which type of hotel is higher, on average?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 8.\nWe observe two unusual values in the summary statistics above – a negative minimum, and a very high maximum). What types of hotels are these? Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room. You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.\nHint: For example, you can filter for the given adr amounts and select the relevant columns.\n\n# add code here\n# pay attention to correctness and code style"
  },
  {
    "objectID": "teaching/Tidyverse/material/hotels-datawrangling.html#data-dictionary",
    "href": "teaching/Tidyverse/material/hotels-datawrangling.html#data-dictionary",
    "title": "Hotel bookings - data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the full data dictionary. Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:  Undefined/SC – no meal package;BB – Bed & Breakfast;  HB – Half board (breakfast and one other meal – usually dinner);  FB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:No Deposit – no deposit was made;Non Refund – a deposit was made in the value of the total stay cost;Refundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:Contract - when the booking has an allotment or other type of contract associated to it;Group – when the booking is associated to a group;Transient – when the booking is not part of a group or contract, and is not associated to other transient booking;Transient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:Canceled – booking was canceled by the customer;Check-Out – customer has checked in but already departed;No-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "teaching/Tidyverse/index.html",
    "href": "teaching/Tidyverse/index.html",
    "title": "Data Wrangling and Visualization with Tidyverse",
    "section": "",
    "text": "Make sure to install and load Tidyverse:\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n\nSchedule\n\n\n\n\ndate\nslides\npractical\ndata\n\n\n\n\n1: Meet the toolkit\n12.04.2024\n\n\n\n\n\n2: Data visualization and ggplot\n19.04.2024\n\n\n\n\n\n3: Visualizing numerical and categorical data\n26.04.2024\n\n\n.zip\n\n\n4: Grammar of data wrangling I\n10.05.2024\n\n \n.zip\n\n\n5: Grammar of data wrangling II\n17.05.2024\n\n\n.zip\n\n\n6: Tidying Data\n23.05.2024\n\n\n.zip\n\n\n7: More Practicals\n07.06.2024\n\n \n.zip"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Projects",
    "section": "",
    "text": "Statistical Entropy Analysis of Network Data\n\n\nIn this project, a general framework for using statistical entropies to capture interdependencies among node and tie variables in multivariate networks is developed.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultigraph Representation of Network Data\n\n\nThe exploratory and confirmatory statistical analysis of multivariate social networks represented as multigraphs.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNetwork of Interconnected Convoys\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Co-Evolution of Network Structure and Individual Outcomes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Dependent Structures in Charachter Networks\n\n\nUsing network analysis to analyze gender representation in popular cinema.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNEXUS1492 - Reconstructing Archaeological Networks\n\n\nReconstructing Archaeological Networks And Their Transformations Across The Historical Divide.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/movienetworks/index.html",
    "href": "project/movienetworks/index.html",
    "title": "Gender Dependent Structures in Charachter Networks",
    "section": "",
    "text": "Since 2019, I’m sporadically working on a project with Pete Jones which aims to apply existing and novel quantitative methods (e.g. relational event models, entropy based natural language processing and multigraph representations), to study the gendered inequalities in popular cinema. See Pete’s website for more information and some awesome packages such as charinet which he has developed on the topic."
  },
  {
    "objectID": "project/movienetworks/index.html#project-summary",
    "href": "project/movienetworks/index.html#project-summary",
    "title": "Gender Dependent Structures in Charachter Networks",
    "section": "",
    "text": "Since 2019, I’m sporadically working on a project with Pete Jones which aims to apply existing and novel quantitative methods (e.g. relational event models, entropy based natural language processing and multigraph representations), to study the gendered inequalities in popular cinema. See Pete’s website for more information and some awesome packages such as charinet which he has developed on the topic."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "",
    "section": "",
    "text": "Hello World\n\n\n\ntest\n\n\n\nThis is a test entry…\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#general",
    "href": "index.html#general",
    "title": "Termeh Shafie",
    "section": "General",
    "text": "General\n\n05.06.2024: Inaugural Professorial Lecture 🤓\nI’ll be giving my inaugural professorial lecture. which is open for anyone who wants join. Expect a lot of big words, personal anecdotes, some mildly amusing jokes, and maybe even a technical hiccup or two 🤓📚✨  Join afterward for finger food and drinks 🥂  📅 Date: June 5th 📍 Venue: Data Theatre ZT1204, University of Konstanz\n\n\n20.02.2024: Multigraphr 0.2.0\nThe new version of multigraphr is published on CRAN. No user facing changes, just improved performance thanks to David Schoch.\n\n\n10.08.2023: Maternity Leave 🐣\nOn parental leave until end of the year.\n\n\n27.07.2023: Associate Professor of Computational Social Science and Data Science\nToday I start my new position as a Professor (Professorin mit Schwerpunkt Lehre) at the Department of Politics and Public Administration, University of Konstanz."
  },
  {
    "objectID": "index.html#recent-publications",
    "href": "index.html#recent-publications",
    "title": "Termeh Shafie",
    "section": "Recent Publications",
    "text": "Recent Publications\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nThe interplay of structural features and observed dissimilarities among centrality indices\n\n\nDec 6, 2023\n\n\n\n\nGoodness of fit tests for random multigraph models\n\n\nJul 21, 2022\n\n\n\n\n\nNo matching items\n\n\n\nall publications"
  },
  {
    "objectID": "index.html#latest-talks",
    "href": "index.html#latest-talks",
    "title": "Termeh Shafie",
    "section": "Latest Talks",
    "text": "Latest Talks\n\n\n\n\n\n\n\n\n\n\nStatistical Analysis & Modeling of Multivariate Networks\n\n\nInaugural Lecture, University of Konstanz\n\n\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n“Statistical Analysis of Multivariate Egocentric Networks”\n\n\nThe XLII Social Networks Conference of INSNA\n\n\n\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n“Statistical Entropy Analysis of Network Data”\n\n\nThe Women in Network Science (WiNS) seminar\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\nNo matching items\n\n\n\nmore talks"
  },
  {
    "objectID": "index.html#r-packages",
    "href": "index.html#r-packages",
    "title": "Termeh Shafie",
    "section": "R packages",
    "text": "R packages\n\n\n\n\n\n\n\n\n\nInstall development version from GitHub for the most recent updates.\n\n\n\n\n\n\n\n\n\n\n\nLatest published version 0.2.0 on CRAN is up to date.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#github-activity",
    "href": "index.html#github-activity",
    "title": "Termeh Shafie",
    "section": "GitHub Activity",
    "text": "GitHub Activity"
  },
  {
    "objectID": "index.html#social-media",
    "href": "index.html#social-media",
    "title": "Termeh Shafie",
    "section": "Social Media",
    "text": "Social Media\n\n \n\n    Toots"
  },
  {
    "objectID": "talks/EUSN2021/index.html",
    "href": "talks/EUSN2021/index.html",
    "title": "Multiplexity Analysis of Networks using Multigraph Representations",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "talks/CMB2022/index.html",
    "href": "talks/CMB2022/index.html",
    "title": "“Analyzing Social Structure using Multigraph Representations”",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "talks/Inaugural-KN/index.html",
    "href": "talks/Inaugural-KN/index.html",
    "title": "Statistical Analysis & Modeling of Multivariate Networks",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Statistical Analysis & Modeling of Multivariate Networks\n\n\nInaugural Lecture, University of Konstanz\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Analyzing Social Structure using Multigraph Representations”\n\n\nPresentation @ Centre Marc Bloch, Berlin\n\n\n\nNov 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Statistical Analysis of Multivariate Egocentric Networks”\n\n\nThe XLII Social Networks Conference of INSNA\n\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Statistical Entropy Analysis of Network Data”\n\n\nThe Women in Network Science (WiNS) seminar\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiplexity Analysis of Networks using Multigraph Representations\n\n\nThe 5th European Conference on Social Networks\n\n\n\nSep 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Goodness of Fit Tests for Random Multigraph Models”\n\n\nNetwork 2021 - A Joint Sunbelt and NetSci Conference\n\n\n\nJul 6, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Gender Dependent Structures of Dialogue Networks in Films”\n\n\nThe 4th European Conference on Social Networks\n\n\n\nSep 9, 2019\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/ontario_sna/index.html",
    "href": "publications/ontario_sna/index.html",
    "title": "Nation Building and Social Signaling in Southern Ontario AD 1350-1650",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/ontario_sna/index.html#abstract",
    "href": "publications/ontario_sna/index.html#abstract",
    "title": "Nation Building and Social Signaling in Southern Ontario AD 1350-1650",
    "section": "Abstract",
    "text": "Abstract\nPottery is a mainstay of archaeological analysis worldwide. Often, high proportions of the pottery recovered from a given site are decorated in some manner. In northern Iroquoia, late pre-contact pottery and early contact decoration commonly occur on collars—thick bands of clay that encircle a pot and extend several centimeters down from the lip. These decorations constitute signals that conveyed information about a pot’s user(s). In southern Ontario the period A.D. 1350 to 1650 witnessed substantial changes in socio-political and settlement systems that included population movement, coalescence of formerly separate communities into large villages and towns, waxing and waning of regional strife, the formation of nations, and finally the development of three confederacies that each occupied distinct, constricted areas. Social network analysis demonstrates that signaling practices changed to reflect these regional patterns. Networks become more consolidated through time ultimately resulting in a “small world” network with small degrees of separation between sites reflecting the integration of communities within and between the three confederacies.\nPLoS ONE 11(5), e0156178"
  },
  {
    "objectID": "publications/isotopes/index.html",
    "href": "publications/isotopes/index.html",
    "title": "Investigating Human Geographic Origins using Dual-Isotope (87Sr/86Sr, d18O) Assignment approaches",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/isotopes/index.html#abstract",
    "href": "publications/isotopes/index.html#abstract",
    "title": "Investigating Human Geographic Origins using Dual-Isotope (87Sr/86Sr, d18O) Assignment approaches",
    "section": "Abstract",
    "text": "Abstract\nSubstantial progress in the application of multiple isotope analyses has greatly improved the ability to identify nonlocal individuals amongst archaeological populations over the past decades. More recently the development of large scale models of spatial isotopic variation (isoscapes) has contributed to improved geographic assignments of human and animal origins. Persistent challenges remain, however, in the accurate identification of individual geographic origins from skeletal isotope data in studies of human (and animal) migration and provenance. In an attempt to develop and test more standardized and quantitative approaches to geographic assignment of individual origins using isotopic data two methods, combining 87Sr/86Sr and d18O isoscapes, are examined for the Circum-Caribbean region 1) an Interval approach using a defined range of fixed isotopic variation per location and 2) a Likelihood assignment approach using univariate and bivariate probability density functions. These two methods are tested with enamel isotope data from a modern sample of known origin from Caracas, Venezuela and further explored with two archaeological samples of unknown origin recovered from Cuba and Trinidad. The results emphasize both the potential and limitation of the different approaches. Validation tests on the known origin sample exclude most areas of the Circum-Caribbean region and correctly highlight Caracas as a possible place of origin with both approaches. The positive validation results clearly demonstrate the overall efficacy of a dual-isotope approach to geoprovenance. The accuracy and precision of geographic assignments may be further improved by better understanding of the relationships between environmental and biological isotope variation; continued development and refinement of relevant isoscapes; and the eventual incorporation of a broader array of isotope proxy data.\nPLoS ONE 12(2), e0172562"
  },
  {
    "objectID": "publications/data_protection/index.html",
    "href": "publications/data_protection/index.html",
    "title": "Data Protection for Online Social Networks and P-Stability for Graphs",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/data_protection/index.html#abstract",
    "href": "publications/data_protection/index.html#abstract",
    "title": "Data Protection for Online Social Networks and P-Stability for Graphs",
    "section": "Abstract",
    "text": "Abstract\nGraphs can be used as a model for online social networks. In this framework, vertices represent individuals and edges relationships between individuals. In recent years, different approaches have been considered to offer data privacy to online social networks and for developing graph protection. Perturbative approaches are formally defined in terms of perturbation and modification of graphs. In this paper, we discuss the concept of P -stability on graphs and its relation to data privacy. The concept of P-stability is rooted in the number of graphs given a fixed degree sequence. In this paper, we show that for any graph there exists a class of P-stable graphs. This result implies that there is a fully polynomial randomized approximation for graph masking for the graphs in the class. In order to further refine the classification of a given graph, we introduce the concept of natural class of a graph. It is based on a class of scale-free networks.\nIEEE Transactions on Emerging Topics in Computing 4(3), 374-381"
  },
  {
    "objectID": "publications/global_local_multigraphs/index.html",
    "href": "publications/global_local_multigraphs/index.html",
    "title": "Analyzing Local and Global Properties of Multigraphs",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/global_local_multigraphs/index.html#abstract",
    "href": "publications/global_local_multigraphs/index.html#abstract",
    "title": "Analyzing Local and Global Properties of Multigraphs",
    "section": "Abstract",
    "text": "Abstract\nThe local structure of undirected multigraphs under two random multigraph models is analyzed and compared. The first model generates multigraphs by randomly coupling pairs of stubs according to a fixed degree sequence so that edge assignments to vertex pair sites are dependent. The second model is a simplification that ignores the dependency between the edge assignments. It is investigated when this ignorance is justified so that the simplified model can be used as an approximation, thus facilitating the structural analysis of network data with multiple relations and loops. The comparison is based on the local properties of multigraphs given by marginal distribution of edge multiplicities and some local properties that are aggregations of global properties.\nJournal of Mathematical Sociology 40(4), 239-264"
  },
  {
    "objectID": "publications/gof_multigraph/index.html",
    "href": "publications/gof_multigraph/index.html",
    "title": "Goodness of fit tests for random multigraph models",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/gof_multigraph/index.html#abstract",
    "href": "publications/gof_multigraph/index.html#abstract",
    "title": "Goodness of fit tests for random multigraph models",
    "section": "Abstract",
    "text": "Abstract\nGoodness of fit tests for two probabilistic multigraph models are presented. The first model is random stub matching given fixed degrees (RSM) so that edge assignments to vertex pair sites are dependent, and the second is independent edge assignments (IEA) according to a common probability distribution. Tests are performed using goodness of fit measures between the edge multiplicity sequence of an observed multigraph, and the expected one according to a simple or composite hypothesis. Test statistics of Pearson type and of likelihood ratio type are used, and the expected values of the Pearson statistic under the different models are derived. Test performances based on simulations indicate that even for small number of edges, the null distributions of both statistics are well approximated by their asymptotic χ2-distribution. The non-null distributions of the test statistics can be well approximated by proposed adjusted χ2-distributions used for power approximations. The influence of RSM on both test statistics is substantial for small number of edges and implies a shift of their distributions towards smaller values compared to what holds true for the null distributions under IEA. Two applications on social networks are included to illustrate how the tests can guide in the analysis of social structure.\nJournal of Applied Statistics"
  },
  {
    "objectID": "publications/hypergraph/index.html",
    "href": "publications/hypergraph/index.html",
    "title": "Hypergraph Representations: A Study of Carib Attacks on Colonial Forces, 1509-1700",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/hypergraph/index.html#abstract",
    "href": "publications/hypergraph/index.html#abstract",
    "title": "Hypergraph Representations: A Study of Carib Attacks on Colonial Forces, 1509-1700",
    "section": "Abstract",
    "text": "Abstract\nNetwork data consisting of recorded historical events can be represented as hyper-graphs where the ties or events can connect any number of nodes or event related attributes. In this paper, we perform a centrality analysis of a directed hypergraph representing attacks by indigenous peoples from the Lesser Antilles on European colonial settlements, 1509-1700. The results of central attacks with respect to at- tacked colonial force, member of attack alliances, and year and location of attack are discussed and compared to a non-relational exploratory analysis of the data. This comparison points to the importance of a mixed methods approach to enhance the analysis and to obtain a complementary understanding of a network study.\npublication: ‘Journal of Historical Network Research 1(1), 52-70’"
  },
  {
    "objectID": "publications/multiplexity/index.html",
    "href": "publications/multiplexity/index.html",
    "title": "Multiplexity Analysis of Networks using Multigraph Representations",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/multiplexity/index.html#abstract",
    "href": "publications/multiplexity/index.html#abstract",
    "title": "Multiplexity Analysis of Networks using Multigraph Representations",
    "section": "Abstract",
    "text": "Abstract\nMultivariate networks comprising several compositional and structural variables can be represented as multigraphs by various forms of aggregations based on vertex attributes. We propose a framework to perform exploratory and confirmatory multiplexity analysis of aggregated multigraphs in order to find relevant associations between vertex and edge attributes. The exploration is performed by comparing frequencies of the different edges within and between aggregated vertex categories, while the confirmatory analysis is performed using derived complexity or multiplexity statistics under different random multigraph models. These statistics are defined by the distribution of edge multiplicities and provide information on the covariation and dependencies of different edges given vertex attributes. The presented approach highlights the need to further analyse and model structural dependencies with respect to edge entrainment. We illustrate the approach by applying it on a well known multivariate network dataset which has previously been analysed in the context of multiplexity.\npublication: Statistical Methods & Applications 30, 1425–1444"
  },
  {
    "objectID": "publications/multivariate_entropy_analysis/index.html",
    "href": "publications/multivariate_entropy_analysis/index.html",
    "title": "Multivariate Entropy Analysis of Network Data",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/multivariate_entropy_analysis/index.html#abstract",
    "href": "publications/multivariate_entropy_analysis/index.html#abstract",
    "title": "Multivariate Entropy Analysis of Network Data",
    "section": "Abstract",
    "text": "Abstract\nMultigraphs with numerical or qualitative attributes defined on vertices and edges can benefit from systematic methods based on multivariate entropies for describing and analysing the interdependencies that are present between vertex and edge attributes. This is here illustrated by application of these tools to a subset of data on the social relations among Renaissance Florentine families collected by John Padgett. Using multivariate entropies we show how it is possible to systematically check for tendencies in data that can be described as independencies or conditional independencies, or as dependencies allowing certain combinations of variables to predict other variables. We also show how different structural models can be tested by divergence measures obtained from the multivariate entropies.\nBulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique 120(1), 45-63"
  },
  {
    "objectID": "publications/reconstructing_arch_nets/index.html",
    "href": "publications/reconstructing_arch_nets/index.html",
    "title": "Reconstructing Archaeological Networks with Structural Holes",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/reconstructing_arch_nets/index.html#abstract",
    "href": "publications/reconstructing_arch_nets/index.html#abstract",
    "title": "Reconstructing Archaeological Networks with Structural Holes",
    "section": "Abstract",
    "text": "Abstract\nModel-based reconstruction is an approach to infer network structures where they cannot be observed. For archaeological networks, several models based on assumptions concerning distance among sites, site size, or costs and benefits have been proposed to infer missing ties. Since these assumptions are formulated at a dyadic level, they do not provide means to express dependencies among ties and therefore include less plausible network scenarios. In this paper we investigate the use of network models that explicitly incorporate tie dependence. In particular, we consider exponential random graph models, and show how they can be applied to reconstruct networks coherent with Burt’s arguments on closure and structural holes (Burt 2001). The approach is illustrated on data from the Middle Bronze Age in the Aegean. authors:\nJournal of Archaeological Method and Theory 25(1), 226-253"
  },
  {
    "objectID": "publications/interplay_str_cent/index.html",
    "href": "publications/interplay_str_cent/index.html",
    "title": "The interplay of structural features and observed dissimilarities among centrality indices",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/interplay_str_cent/index.html#abstract",
    "href": "publications/interplay_str_cent/index.html#abstract",
    "title": "The interplay of structural features and observed dissimilarities among centrality indices",
    "section": "Abstract",
    "text": "Abstract\nAn abundance of centrality indices has been proposed which capture the importance of nodes in a network based on different structural features. While there remains a persistent belief that similarities in outcomes of indices is contingent on their technical definitions, a growing body of research shows that structural features affect observed similarities more than technicalities. We conduct a series of experiments on artificial networks to trace the influence of specific structural features on the similarity of indices which confirm previous results in the literature. Our analysis on 1163 real-world networks, however, shows that little of the observations on synthetic networks convincingly carry over to empirical settings. Our findings suggest that although it seems clear that (dis)similarities among centralities depend on structural properties of the network, using correlation type analyses do not seem to be a promising approach to uncover such connections.\nSocial Networks"
  },
  {
    "objectID": "publications/aggregated_triads/index.html",
    "href": "publications/aggregated_triads/index.html",
    "title": "Random Multigraphs and Aggregated Triads with Fixed Degrees",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/aggregated_triads/index.html#abstract",
    "href": "publications/aggregated_triads/index.html#abstract",
    "title": "Random Multigraphs and Aggregated Triads with Fixed Degrees",
    "section": "Abstract",
    "text": "Abstract\nRandom multigraphs with fixed degrees are obtained by the configuration model or by so called random stub matching. New combinatorial results are given for the global probability distribution of edge multiplicities and its marginal local distributions of loops and edges. The number of multigraphs on triads is determined for arbitrary degrees, and aggregated triads are shown to be useful for analyzing regular and almost regular multigraphs. Relationships between entropy and complexity are given and numerically illustrated for multigraphs with different number of vertices and specified average and variance for the degrees.\nNetwork Science 6(2), 232-250"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "The interplay of structural features and observed dissimilarities among centrality indices\n\n\nThe association of network topology with dissimilarities of indices is assessed\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoodness of fit tests for random multigraph models\n\n\nGoodness of fit tests for different probability models for random multigraphs.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiplexity Analysis of Networks using Multigraph Representations\n\n\nA method for performing multiplexity analysis in social networks with several node covariates is presented.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Network Analysis\n\n\nA review chapter on social network analysis aimed towards undergraduate students.\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Framework for Reconstructing Archaeological Networks using Exponential Random Graph Models\n\n\nWe present a general framework in which we combine exponential random graph models with archaeological substantiations of mechanisms for network formation.\n\n\n\n\n\n\n\n\n\n\n\n\n\nReconstructing Archaeological Networks with Structural Holes\n\n\nWe consider exponential random graph models, and show how they can be applied to reconstruct networks coherent with Burt’s arguments on closure and structural holes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Multigraphs and Aggregated Triads with Fixed Degrees\n\n\nNew combinatorial results are given for the global probability distribution of edge multiplicities and its marginal local distributions of loops and edges.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypergraph Representations: A Study of Carib Attacks on Colonial Forces, 1509-1700\n\n\nWe perform a centrality analysis of a directed hypergraph representing attacks by indigenous peoples from the Lesser Antilles on European colonial settlements, 1509-1700.\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Human Geographic Origins using Dual-Isotope (87Sr/86Sr, d18O) Assignment approaches\n\n\nWe develop and test more standardized and quantitative approaches to geographic assignment of individual origins using multivariate isotopic data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Local and Global Properties of Multigraphs\n\n\nThe local and global structures of undirected multigraphs under two random multigraph models are analyzed and compared.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNation Building and Social Signaling in Southern Ontario AD 1350-1650\n\n\nSocial network analysis is used to demonstrates the signaling practices reflecting regional patterns.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate Entropy Analysis of Network Data\n\n\nWe show how it is possible to systematically check for tendencies in data, such as independencies or conditional independencies, using multivariate entropies.\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Protection for Online Social Networks and P-Stability for Graphs\n\n\nWe consider different approaches for data privacy in online social networks and for developing graph protection.\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Multigraph Approach to Social Network Analysis\n\n\nThe theoretical background for analyzing multivariate social networks using multigraph representations is introduced.\n\n\n\n\n\n\n\n\n\n\n\n\n\nComplexity of Families of Multigraphs\n\n\nComplexity measured for multigraphs are specified and their applicability is discussed.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/complexity_multigraphs/index.html",
    "href": "publications/complexity_multigraphs/index.html",
    "title": "Complexity of Families of Multigraphs",
    "section": "",
    "text": "pdf"
  },
  {
    "objectID": "publications/complexity_multigraphs/index.html#abstract",
    "href": "publications/complexity_multigraphs/index.html#abstract",
    "title": "Complexity of Families of Multigraphs",
    "section": "Abstract",
    "text": "Abstract\nThis article describes families of finite multigraphs with labeled or unlabeled edges and vertices. It shows how size and complexity vary for different types of equivalence classes of graphs defined by ignoring only edge labels or ignoring both edge and vertex labels. Complexity is quantified by the distribution of edge multiplicities, and different complexity measures are discussed. Basic occupancy models for multigraphs are used to illustrate different graph distributions on isomorphism and complexity. The loss of information caused by ignoring edge and vertex labels is quantified by entropy and joint information that provide tools for studying properties of and relations between different graph families.\nIn 2012 JSM Proceedings: Papers Presented at the Joint Statistical Meetings, San Diego, California, July 28-August 2, 2012, and Other ASA-sponsored Conferences, American Statistical Association, 2012"
  },
  {
    "objectID": "publications/sna_chapter/index.html",
    "href": "publications/sna_chapter/index.html",
    "title": "Social Network Analysis",
    "section": "",
    "text": "book chapter"
  },
  {
    "objectID": "publications/sna_chapter/index.html#abstract",
    "href": "publications/sna_chapter/index.html#abstract",
    "title": "Social Network Analysis",
    "section": "Abstract",
    "text": "Abstract\nSocial networks comprise a set of nodes or actors (representing, e.g., individuals, groups, organisations) that are pairwise connected by edges or ties (representing, e.g., relationships, interactions, communication). The social systems arising exhibit patterns of interest, and social network analysis is the study of how and why these patterns emerge, sustain, and evolve. Of primary interest is thus to understand and describe the social processes that support the observed structure. These processes are founded in theories about network representation and theories about observed social phenomena. The benefit from network conceptualisation is thus obtained by outlining the association and distinction between these theories. This entry serves as an introduction to fundamental network concepts and analytical approaches, their potential for studying social phenomena, and a description of why they are central to theoretical constructs. This entry also provides a short introduction to statistical network modelling for cross-sectional and longitudinal network data.\nSAGE Research Methods Foundations"
  },
  {
    "objectID": "publications/multigraph_approach/index.html",
    "href": "publications/multigraph_approach/index.html",
    "title": "A Multigraph Approach to Social Network Analysis",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/multigraph_approach/index.html#abstract",
    "href": "publications/multigraph_approach/index.html#abstract",
    "title": "A Multigraph Approach to Social Network Analysis",
    "section": "Abstract",
    "text": "Abstract\nMultigraphs are graphs where multiple edges and edge loops are permitted. The main purpose of this article is to show the versatility of a multigraph approach when analysing social networks. Multigraph data structures are described and it is exemplified how they naturally occur in many contexts but also how they can be constructed by different kinds of aggregation in graphs. Special attention is given to a random multigraph model based on independent edge assignments to sites of vertex pairs and some useful measures of the local and global structure under this model are presented. Further, it is shown how some general measures of simplicity and complexity of multigraphs are easily handled under the present model.\n‘Journal of Social Structure 16, 1-22’"
  },
  {
    "objectID": "publications/ergm_framework_arch/index.html",
    "href": "publications/ergm_framework_arch/index.html",
    "title": "A Framework for Reconstructing Archaeological Networks using Exponential Random Graph Models",
    "section": "",
    "text": "journal"
  },
  {
    "objectID": "publications/ergm_framework_arch/index.html#abstract",
    "href": "publications/ergm_framework_arch/index.html#abstract",
    "title": "A Framework for Reconstructing Archaeological Networks using Exponential Random Graph Models",
    "section": "Abstract",
    "text": "Abstract\nReconstructing ties between archaeological contexts may contribute to explain and describe a variety of past social phenomena. Several models have been formulated to infer the structure of such archaeological networks. The underlying propositions about mechanisms regulating the formation of ties in the past are often articulated on a dyadic basis and therefore rarely account for dependencies among ties. Here, we present a general framework in which we combine exponential random graph models with archaeological substantiations of mechanisms that may be responsible for network formation to account for tie dependence. We use data collected over a set of sites in the Caribbean during the period AD 100 - 400 to illustrate the steps to obtain a network reconstruction.\nJournal of Archaeological Method and Theory 27, 192-219"
  },
  {
    "objectID": "talks/WiNS2022/index.html",
    "href": "talks/WiNS2022/index.html",
    "title": "“Statistical Entropy Analysis of Network Data”",
    "section": "",
    "text": "Slides\n\n\nExamples\n\n\nVideo"
  },
  {
    "objectID": "talks/NETWORKS2021/index.html",
    "href": "talks/NETWORKS2021/index.html",
    "title": "“Goodness of Fit Tests for Random Multigraph Models”",
    "section": "",
    "text": "Slides\n\n\nVideo"
  },
  {
    "objectID": "talks/SUNBELT2022/index.html",
    "href": "talks/SUNBELT2022/index.html",
    "title": "“Statistical Analysis of Multivariate Egocentric Networks”",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "talks/EUSN2019/index.html",
    "href": "talks/EUSN2019/index.html",
    "title": "“Gender Dependent Structures of Dialogue Networks in Films”",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Termeh Shafie",
    "section": "",
    "text": "👋 Hi, I’m Termeh\nI’m a statistician with more than a decade of experience in developing methods and models to analyze multivariate social networks. I’m also the developer and maintainer of two R packages on the topic.\nInterdisciplinary applications are close to heart and I have had many such collaborations in different branches of computational social science and digital humanities. You can find information on some of the methodological and empirical projects that I have worked on or currently work on here."
  },
  {
    "objectID": "about/index.html#education",
    "href": "about/index.html#education",
    "title": "Termeh Shafie",
    "section": "Education",
    "text": "Education\n\nPhD in Statistics | 2013 | Stockholm University | Stockholm, Sweden\nLicentiate of Philosophy in Statistic | 2008 | Umeå University | Umeå Sweden\nMaster of Social Science (major in Statistics) | 2006 | Umeå University | Umeå Sweden\nMaster of Science in Public Administration and Economics | 2006 | Umeå University | Umeå Sweden"
  },
  {
    "objectID": "about/index.html#experience",
    "href": "about/index.html#experience",
    "title": "Termeh Shafie",
    "section": "Experience",
    "text": "Experience\n\nAssociate Professor of Computational Social Science and Data Science | July 2023 – | Department of Politics and Public Administration | Center for Data and Methods | University of Konstanz\nInterim Professor | Apr 2023 – July 2023 | Department of Politics and Public Administration | University of Konstanz\nSenior Researcher | Jul 2022 – Mar 2023 | Department of Computational Social Science GESIS – Leibniz Institute for the Social Sciences\nLecturer in Social Statistics | Jul 2018 – Apr 2022 | Department of Social Statistics | The University of Manchester\nPostdoctoral Researcher | Nov 2017 – Jun 2018 | Department of Humanities, Social and Political Sciences | ETH Zürich\nPostdoctoral Researcher | Sep 2013 – Oct 2017 | Department of Computer and Information Science | University of Konstanz"
  },
  {
    "objectID": "project/seand/index.html",
    "href": "project/seand/index.html",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "",
    "text": "In multivariate statistics, there is an abundance of different measures of centrality and spread, many of which cannot be applied on variables measured on nominal or ordinal scale. Since network data in majority comprises such variables, alternative measures for analyzing spread, flatness and association is needed. This is also of particular relevance given the special feature of interdependent observations in networks.\nMultivariate entropy analysis is a general statistical method for analyzing and finding dependence structure in data consisting of repeated observations of variables with a common domain and with discrete finite range spaces. Only nominal scale is required for each variable, so only the size of the variable’s range space is important but not its actual values. Variables on ordinal or numerical scales, even continuous numerical scales, can be used, but they should be aggregated so that their ranges match the number of available repeated observations. By investigating the frequencies of occurrences of joint variable outcomes, complicated dependence structures, partial independence and conditional independence as well as redundancies and functional dependence can be found.\nSince 2015, I am working with Ove Frank and Krzysztof Nowicki on a project in which we build a systematic framework for using statistical entropy tools to analyze network data. A forthcoming monograph on the topic is expected in the coming year.\nThe proposed framework is implemented in the R package ‘netropy’ and a description of various functions implemented in the package are given in the following. More details are provided in the package vignettes and the references listed."
  },
  {
    "objectID": "project/seand/index.html#project-summary",
    "href": "project/seand/index.html#project-summary",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "",
    "text": "In multivariate statistics, there is an abundance of different measures of centrality and spread, many of which cannot be applied on variables measured on nominal or ordinal scale. Since network data in majority comprises such variables, alternative measures for analyzing spread, flatness and association is needed. This is also of particular relevance given the special feature of interdependent observations in networks.\nMultivariate entropy analysis is a general statistical method for analyzing and finding dependence structure in data consisting of repeated observations of variables with a common domain and with discrete finite range spaces. Only nominal scale is required for each variable, so only the size of the variable’s range space is important but not its actual values. Variables on ordinal or numerical scales, even continuous numerical scales, can be used, but they should be aggregated so that their ranges match the number of available repeated observations. By investigating the frequencies of occurrences of joint variable outcomes, complicated dependence structures, partial independence and conditional independence as well as redundancies and functional dependence can be found.\nSince 2015, I am working with Ove Frank and Krzysztof Nowicki on a project in which we build a systematic framework for using statistical entropy tools to analyze network data. A forthcoming monograph on the topic is expected in the coming year.\nThe proposed framework is implemented in the R package ‘netropy’ and a description of various functions implemented in the package are given in the following. More details are provided in the package vignettes and the references listed."
  },
  {
    "objectID": "project/seand/index.html#r-package-netropy",
    "href": "project/seand/index.html#r-package-netropy",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "R package netropy",
    "text": "R package netropy\n\n\nPackage overview\n  \nThis package introduces these entropy tools in the context of network data. Brief description of various functions implemented in the package are given in the following but more details are provided in the package vignettes and the references listed.\n\n\nInstallation\nYou can install the released version of netropy from CRAN with:\ninstall.packages(\"netropy\")\nThe development version from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"termehs/netropy\")\nTo load the package:\n\nlibrary('netropy')\n\n\n\nLoading internal data\nThe different entropy tools are explained and illustrated by exploring data from a network study of a corporate law firm, which has previously been analysed by several authors (link). The data set is included in the package as a list with objects representing adjacency matrices for each of the three networks advice (directed), friendship (directed) and co-work (undirected), together with a data frame comprising 8 attributes on each of the 71 lawyers.\nTo load the data, extract each object and assign the correct names to them:\n\ndata(lawdata) \nadj.advice &lt;- lawdata[[1]]\nadj.friend &lt;- lawdata[[2]]\nadj.cowork &lt;-lawdata[[3]]\ndf.att &lt;- lawdata[[4]]"
  },
  {
    "objectID": "project/seand/index.html#variable-domains-and-data-editing",
    "href": "project/seand/index.html#variable-domains-and-data-editing",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "Variable domains and data editing",
    "text": "Variable domains and data editing\nA requirement for the applicability of these entropy tools is the specification of discrete variables with finite range spaces on the same domain: either node attributes/vertex variables, edges/dyad variables or triad variables. These can be either observed or transformed as shown in the following using the above example data set.\nWe have 8 vertex variables with 71 observations, two of which (years and age) are numerical and needs categorization based on their cumulative distributions. This categorization is in details described in the vignette “variable domains and data editing”. Here we just show the new dataframe created (note that variable senior is omitted as it only comprises unique values and that we edit all variable to start from 0):\n\natt.var &lt;-\n  data.frame(\n    status   = df.att$status-1,\n    gender   = df.att$gender,\n    office   = df.att$office-1,\n    years    = ifelse(df.att$years &lt;= 3,0,\n                      ifelse(df.att$years &lt;= 13,1,2)),\n    age      = ifelse(df.att$age &lt;= 35,0,\n                      ifelse(df.att$age &lt;= 45,1,2)),\n    practice = df.att$practice,\n    lawschool= df.att$lawschool-1\n    )\nhead(att.var)\n\n  status gender office years age practice lawschool\n1      0      1      0     2   2        1         0\n2      0      1      0     2   2        0         0\n3      0      1      1     1   2        1         0\n4      0      1      0     2   2        0         2\n5      0      1      1     2   2        1         1\n6      0      1      1     2   2        1         0\n\n\nThese vertex variables can be transformed into dyad variables by using the function get_dyad_var(). Observed node attributes in the dataframe att_var are then transformed into pairs of individual attributes. For example, status with binary outcomes is transformed into dyads having 4 possible outcomes (0,0), (0,1), (1,0), (1,1):\n\ndyad.status    &lt;- get_dyad_var(att.var$status, type = 'att')\ndyad.gender    &lt;- get_dyad_var(att.var$gender, type = 'att')\ndyad.office    &lt;- get_dyad_var(att.var$office, type = 'att')\ndyad.years     &lt;- get_dyad_var(att.var$years, type = 'att')\ndyad.age       &lt;- get_dyad_var(att.var$age, type = 'att')\ndyad.practice  &lt;- get_dyad_var(att.var$practice, type = 'att')\ndyad.lawschool &lt;- get_dyad_var(att.var$lawschool, type = 'att')\n\nSimilarly, dyad variables can be created based on observed ties. For the undirected edges, we use indicator variables read directly from the adjacency matrix for the dyad in question, while for the directed ones (advice and friendship) we have pairs of indicators representing sending and receiving ties with 4 possible outcomes :\n\ndyad.cwk    &lt;- get_dyad_var(adj.cowork, type = 'tie')\ndyad.adv    &lt;- get_dyad_var(adj.advice, type = 'tie')\ndyad.frn    &lt;- get_dyad_var(adj.friend, type = 'tie')\n\nAll 10 dyad variables are merged into one data frame for subsequent entropy analysis:\n\ndyad.var &lt;-\n  data.frame(cbind(status   = dyad.status$var,\n                  gender    = dyad.gender$var,\n                  office    = dyad.office$var,\n                  years     = dyad.years$var,\n                  age       = dyad.age$var,\n                  practice  = dyad.practice$var,\n                  lawschool = dyad.lawschool$var,\n                  cowork    = dyad.cwk$var,\n                  advice    = dyad.adv$var,\n                  friend    = dyad.frn$var)\n                  )\nhead(dyad.var)\n\n  status gender office years age practice lawschool cowork advice friend\n1      3      3      0     8   8        1         0      0      3      2\n2      3      3      3     5   8        3         0      0      0      0\n3      3      3      3     5   8        2         0      0      1      0\n4      3      3      0     8   8        1         6      0      1      2\n5      3      3      0     8   8        0         6      0      1      1\n6      3      3      1     7   8        1         6      0      1      1\n\n\nA similar function get_triad_var() is implemented for transforming vertex variables and different relation types into triad variables. This is described in more detail in the vignette “variable domains and data editing”."
  },
  {
    "objectID": "project/seand/index.html#univariate-bivariate-and-trivariate-entropies",
    "href": "project/seand/index.html#univariate-bivariate-and-trivariate-entropies",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "Univariate, bivariate and trivariate entropies",
    "text": "Univariate, bivariate and trivariate entropies\nThe function entropy_bivar() computes the bivariate entropies of all pairs of variables in the dataframe. The output is given as an upper triangular matrix with cells giving the bivariate entropies of row and column variables. The diagonal thus gives the univariate entropies for each variable in the dataframe:\n\nH2 &lt;- entropy_bivar(dyad.var)\nH2\n\n          status gender office years   age practice lawschool cowork advice\nstatus     1.493  2.868  3.640 3.370 3.912    3.453     4.363  2.092  2.687\ngender        NA  1.547  3.758 3.939 4.274    3.506     4.439  2.158  2.785\noffice        NA     NA  2.239 4.828 4.901    4.154     5.058  2.792  3.388\nyears         NA     NA     NA 2.671 4.857    4.582     5.422  3.268  3.868\nage           NA     NA     NA    NA 2.801    4.743     5.347  3.411  4.028\npractice      NA     NA     NA    NA    NA    1.962     4.880  2.530  3.127\nlawschool     NA     NA     NA    NA    NA       NA     2.953  3.567  4.186\ncowork        NA     NA     NA    NA    NA       NA        NA  0.615  1.687\nadvice        NA     NA     NA    NA    NA       NA        NA     NA  1.248\nfriend        NA     NA     NA    NA    NA       NA        NA     NA     NA\n          friend\nstatus     2.324\ngender     2.415\noffice     3.044\nyears      3.483\nage        3.637\npractice   2.831\nlawschool  3.812\ncowork     1.456\nadvice     1.953\nfriend     0.881\n\n\nBivariate entropies can be used to detect redundant variables that should be omitted from the dataframe for further analysis. This occurs when the univariate entropy for a variable is equal to the bivariate entropies for pairs including that variable. As seen above, the dataframe dyad.var has no redundant variables. This can also be checked using the function redundancy() which yields a binary matrix as output indicating which row and column variables are hold the same information:\n\nredundancy(dyad.var)\n\nNULL\n\n\nMore examples of using the function redundancy() is given in the vignette “univariate bivariate and trivariate entropies”.\nTrivariate entropies can be computed using the function entropy_trivar() which returns a dataframe with the first three columns representing possible triples of variables V1,V2, and V3 from the dataframe in question, and their entropies H(V1,V2,V3) as the fourth column. We illustrated this on the dataframe dyad.var:\n\nH3 &lt;- entropy_trivar(dyad.var)\nhead(H3, 10) # view first 10 rows of dataframe\n\n       V1     V2        V3 H(V1,V2,V3)\n1  status gender    office       4.938\n2  status gender     years       4.609\n3  status gender       age       5.129\n4  status gender  practice       4.810\n5  status gender lawschool       5.664\n6  status gender    cowork       3.464\n7  status gender    advice       4.048\n8  status gender    friend       3.685\n9  status office     years       5.321\n10 status office       age       5.721"
  },
  {
    "objectID": "project/seand/index.html#joint-entropy-and-association-graphs",
    "href": "project/seand/index.html#joint-entropy-and-association-graphs",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "Joint entropy and association graphs",
    "text": "Joint entropy and association graphs\nJoint entropies is a non-negative measure of association among pairs of variables. It is equal to 0 if and only if two variables are completely independent of each other.\nThe function joint_entropy() computes the joint entropies between all pairs of variables in a given dataframe and returns a list consisting of the upper triangular joint entropy matrix (univariate entropies in the diagonal) and a dataframe giving the frequency distributions of unique joint entropy values. A function argument specifies the precision given in number of decimals for which the frequency distribution of unique entropy values is created (default is 3). Applying the function on the dataframe dyad.var with two decimals:\n\nJ &lt;- joint_entropy(dyad.var, 2)\nJ$matrix\n\n          status gender office years  age practice lawschool cowork advice\nstatus      1.49   0.17   0.09  0.79 0.38     0.00      0.08   0.02   0.05\ngender        NA   1.55   0.03  0.28 0.07     0.00      0.06   0.00   0.01\noffice        NA     NA   2.24  0.08 0.14     0.05      0.13   0.06   0.10\nyears         NA     NA     NA  2.67 0.61     0.05      0.20   0.02   0.05\nage           NA     NA     NA    NA 2.80     0.02      0.41   0.01   0.02\npractice      NA     NA     NA    NA   NA     1.96      0.04   0.05   0.08\nlawschool     NA     NA     NA    NA   NA       NA      2.95   0.00   0.01\ncowork        NA     NA     NA    NA   NA       NA        NA   0.62   0.18\nadvice        NA     NA     NA    NA   NA       NA        NA     NA   1.25\nfriend        NA     NA     NA    NA   NA       NA        NA     NA     NA\n          friend\nstatus      0.05\ngender      0.01\noffice      0.08\nyears       0.07\nage         0.05\npractice    0.01\nlawschool   0.02\ncowork      0.04\nadvice      0.18\nfriend      0.88\n\nJ$freq\n\n      j  #(J = j) #(J &gt;= j)\n1  0.79         1         1\n2  0.61         1         2\n3  0.41         1         3\n4  0.38         1         4\n5  0.28         1         5\n6   0.2         1         6\n7  0.18         2         8\n8  0.17         1         9\n9  0.14         1        10\n10 0.13         1        11\n11  0.1         1        12\n12 0.09         1        13\n13 0.08         4        17\n14 0.07         2        19\n15 0.06         2        21\n16 0.05         7        28\n17 0.04         2        30\n18 0.03         1        31\n19 0.02         5        36\n20 0.01         5        41\n21    0         4        45\n\n\nAs seen, the strongest association is between the variables status and years with joint entropy values of 0.79. We have independence (joint entropy value of 0) between two pairs of variables: (status,practice), (practise,gender), (cowork,gender),and (cowork,lawschool).\nThese results can be illustrated in a association graph using the function assoc_graph() which returns a ggraph object in which nodes represent variables and links represent strength of association (thicker links indicate stronger dependence). To use the function we need to load the ggraph library and to determine a threshold which the graph drawn is based on. We set it to 0.15 so that we only visualize the strongest associations\n\nlibrary(ggraph)\nassoc_graph(dyad.var, 0.15)\n\n\n\n\n\n\n\n\nGiven this threshold, we see isolated and disconnected nodes representing independent variables. We note strong dependence between the three dyadic variables status,years and age, but also a somewhat strong dependence among the three variables lawschool, years and age, and the three variables status, years and gender. The association graph can also be interpreted as a tendency for relations cowork and friend to be independent conditionally on relation advice, that is, any dependence between dyad variables cowork and friend is explained by advice.\nA threshold that gives a graph with reasonably many small independent or conditionally independent subsets of variables can be considered to represent a multivariate model for further testing.\nMore details and examples of joint entropies and association graphs are given in the vignette “joint entropies and association graphs”."
  },
  {
    "objectID": "project/seand/index.html#prediction-power-based-on-expected-conditional-entropies",
    "href": "project/seand/index.html#prediction-power-based-on-expected-conditional-entropies",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "Prediction power based on expected conditional entropies",
    "text": "Prediction power based on expected conditional entropies\nThe function prediction_power() computes prediction power when pairs of variables in a given dataframe are used to predict a third variable from the same dataframe. The variable to be predicted and the dataframe in which this variable also is part of is given as input arguments, and the output is an upper triangular matrix giving the expected conditional entropies of pairs of row and column variables (denoted \\(X\\) and \\(Y\\)) of the matrix, i.e. EH(Z|X,Y) where \\(Z\\) is the variable to be predicted. The diagonal gives EH(Z|X) , that is when only one variable as a predictor. Note that NA’s are in the row and column representing the variable being predicted.\nAssume we are interested in predicting variable status (that is whether a lawyer in the data set is an associate or partner). This is done by running the following syntax\n\nprediction_power('status', dyad.var)\n\n          status gender office years   age practice lawschool cowork advice\nstatus        NA     NA     NA    NA    NA       NA        NA     NA     NA\ngender        NA  1.375  1.180 0.670 0.855    1.304     1.225  1.306  1.263\noffice        NA     NA  2.147 0.493 0.820    1.374     1.245  1.373  1.325\nyears         NA     NA     NA 2.265 0.573    0.682     0.554  0.691  0.667\nage           NA     NA     NA    NA 1.877    1.089     0.958  1.087  1.052\npractice      NA     NA     NA    NA    NA    2.446     1.388  1.459  1.410\nlawschool     NA     NA     NA    NA    NA       NA     3.335  1.390  1.337\ncowork        NA     NA     NA    NA    NA       NA        NA  2.419  1.400\nadvice        NA     NA     NA    NA    NA       NA        NA     NA  2.781\nfriend        NA     NA     NA    NA    NA       NA        NA     NA     NA\n          friend\nstatus        NA\ngender     1.270\noffice     1.334\nyears      0.684\nage        1.058\npractice   1.427\nlawschool  1.350\ncowork     1.411\nadvice     1.407\nfriend     3.408\n\n\nFor better readability, the powers of different predictors can be conveniently compared by using prediction plots that display a color matrix with rows for \\(X\\) and columns for \\(Y\\) with darker colors in the cells when we have higher prediction power for \\(Z\\).\nMore details and examples of expected conditional entropies and prediction power are given in the package vignette."
  },
  {
    "objectID": "project/seand/index.html#references",
    "href": "project/seand/index.html#references",
    "title": "Statistical Entropy Analysis of Network Data",
    "section": "References",
    "text": "References\nParts of the theoretical background is provided in the package vignettes, but for more details, consult the following literature:\n\nFrank, O., & Shafie, T. (2016). Multivariate entropy analysis of network data. Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique, 129(1), 45-63. link\nNowicki, K., Shafie, T., & Frank, O. (Forthcoming 2022). Statistical Entropy Analysis of Network Data."
  },
  {
    "objectID": "project/rmm/index.html",
    "href": "project/rmm/index.html",
    "title": "Multigraph Representation of Network Data",
    "section": "",
    "text": "Multigraphs are network representations in which multiple edges and edge loops (self edges) are permitted. Multigraph data structure can be observed directly but the possibility to obtain multigraphs using blocking, aggregation and scaling makes them widely applicable.\nFor the past decade, I’ve been working on a statistical framework for analyzing network data using this representation. I have developed different multigraph multigraph models and derived several statistics under these models that can be used to analyse local and global network properties in order to convey important social phenomena and processes. The latest contribution in this framework is formal goodness of fit tests for the developed probability models for random multigraphs.\nThe proposed framework is in full implemented in the R package ‘multigraphr’ and a description of various functions implemented in the package are given in the following. More details are provided in the package vignetteand the references listed."
  },
  {
    "objectID": "project/rmm/index.html#project-summary",
    "href": "project/rmm/index.html#project-summary",
    "title": "Multigraph Representation of Network Data",
    "section": "",
    "text": "Multigraphs are network representations in which multiple edges and edge loops (self edges) are permitted. Multigraph data structure can be observed directly but the possibility to obtain multigraphs using blocking, aggregation and scaling makes them widely applicable.\nFor the past decade, I’ve been working on a statistical framework for analyzing network data using this representation. I have developed different multigraph multigraph models and derived several statistics under these models that can be used to analyse local and global network properties in order to convey important social phenomena and processes. The latest contribution in this framework is formal goodness of fit tests for the developed probability models for random multigraphs.\nThe proposed framework is in full implemented in the R package ‘multigraphr’ and a description of various functions implemented in the package are given in the following. More details are provided in the package vignetteand the references listed."
  },
  {
    "objectID": "project/rmm/index.html#r-package-multigraphr",
    "href": "project/rmm/index.html#r-package-multigraphr",
    "title": "Multigraph Representation of Network Data",
    "section": "R package multigraphr",
    "text": "R package multigraphr\n\nPackage overview\n  \nThis package introduces the multigraph framework for analyzing social network data. Brief description of various functions implemented in the package are given in the following but more details are provided in the package vignettes and the references listed.\n\n\nInstallation\nYou can install the released version of multigraphr from CRAN with:\ninstall.packages(\"multigraphr\")\nThe development version from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"termehs/multigraphr\")"
  },
  {
    "objectID": "project/rmm/index.html#multigraphs-and-applicability",
    "href": "project/rmm/index.html#multigraphs-and-applicability",
    "title": "Multigraph Representation of Network Data",
    "section": "Multigraphs and applicability",
    "text": "Multigraphs and applicability\nMultigraphs are network representations in which multiple edges and edge loops (self edges) are permitted. These data structures can be either directly observed or aggregated by classifying or cross-classifying node attributes into meta nodes. For the latter case, within group edges correspond to self-edges. See example below where the original graph with 15 nodes and 12 edges (left) is aggregated based on node categories into a small multigraph with 4 nodes (right).\n\nEdge aggregation can also be used to obtain multigraphs. Assume that we study a graph with three different types of relations over three periods of time: \nIf we aggregate over time periods, we obtain for each edge category a multigraph for the total time period of three days:\n\nFor more details on these kinds of aggregations, see Shafie (2015;2016)."
  },
  {
    "objectID": "project/rmm/index.html#multigraph-representation-of-network-data",
    "href": "project/rmm/index.html#multigraph-representation-of-network-data",
    "title": "Multigraph Representation of Network Data",
    "section": "Multigraph representation of network data",
    "text": "Multigraph representation of network data\nMultigraphs are represented by their edge multiplicity sequence M with elements M(i,j), denoting the number of edges at vertex pair sites (i,j) ordered according to (1,1) &lt; (1,2) &lt;···&lt; (1,n) &lt; (2,2) &lt; (2,3) &lt;···&lt; (n,n), where n is number of nodes. The number of vertex pair sites is given by r = n(n+1)/2.\n\nRandom multigraph models\nTwo probability models for generating undirected random multigraphs are implemented in the package together with several statistics under these two models. Moreover, functions for goodness of fit tests are available for the presented models.\nNote that some of the functions are only practical for small scale multigraphs.\nThe first model is obtained by random stub matching (RSM) given observed degree sequence of a multigraphs, so that edge assignments to vertex pair sites are dependent. The second is obtained by independent edge assignments (IEA) according to a common probability distribution. There are two ways in which an approximate IEA model can be obtained from an RSM model, thus facilitating the structural analysis. These two ways are\n\nindependent stub assignment (ISA)\nindependent edge assignment of stubs (IEAS)\n\n(Shafie, 2016).\n\n\nExample\n\nlibrary('multigraphr')\n\nConsider a small graph on 3 nodes and the following adjacency matrix:\n\nA &lt;-  matrix(c(1, 1, 0, \n               1, 2, 2, \n               0, 2, 0), \n             nrow = 3, ncol = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    1    1    0\n[2,]    1    2    2\n[3,]    0    2    0\n\n\nThe degree sequence of the multigraph has double counted diagonals (edge stubs for loops) and is given by\n\nD &lt;- get_degree_seq(adj = A, type = 'graph')\nD\n\n[1] 3 7 2\n\n\nso that number of edges in the multigraph is half the sum of the degree sequence which is equal to 6.\nThe RSM model given observed degree sequence shows the sample space consists of 7 possible multigraphs, as represented by their multiplicity sequence m.seq (each row correspond to the edge multiplicity sequence of a unique multigraph):\n\nrsm_1 &lt;- rsm_model(deg.seq = D)\nrsm_1$m.seq\n\n  M11 M12 M13 M22 M23 M33\n1   1   1   0   3   0   1\n2   1   1   0   2   2   0\n3   1   0   1   3   1   0\n4   0   3   0   2   0   1\n5   0   3   0   1   2   0\n6   0   2   1   2   1   0\n7   0   1   2   3   0   0\n\n\nwith probabilities associated with each multigraph, together with statistics ‘number of loops’, ‘number of multiple edges’ and ‘simple graphs or not’:\n\nrsm_1$prob.dists\n\n    prob.rsm loops multiedges simple\n1 0.03030303     5          1      0\n2 0.18181818     3          3      0\n3 0.06060606     4          2      0\n4 0.06060606     3          3      0\n5 0.24242424     1          5      0\n6 0.36363636     2          4      0\n7 0.06060606     3          3      0\n\n\nConsider using the IEA model to approximate the RSM model so that edge assignment probabilities are functions of observed degree sequence. Note that the sample space for multigraphs is much bigger than for the RSM model so the multiplicity sequences are not printed (they can be found using the function get_edgemultip_seq for very small multigraphs and their probabilities can be found using the multinomial distribution). The following shows the number of multigraphs under either of the IEA models:\n\nieas_1 &lt;-   iea_model(adj = A , type = 'graph',  model = 'IEAS', K = 0, apx = TRUE)\nieas_1$nr.multigraphs\n\n[1] 462"
  },
  {
    "objectID": "project/rmm/index.html#statistics-to-analyze-structural-properties",
    "href": "project/rmm/index.html#statistics-to-analyze-structural-properties",
    "title": "Multigraph Representation of Network Data",
    "section": "Statistics to analyze structural properties",
    "text": "Statistics to analyze structural properties\nThese statistics include number of loops (indicator of e.g. homophily) and number of multiple edges (indicator of e.g. multiplexity/interlocking), which are implemented in the package together with their probability distributions, moments and interval estimates under the different multigraph models.\n\nExample (cont’d)\nUnder the RSM model, the first two moments and interval estimates of the statistics M1 = ‘number of loops’ and M2 = ‘number of multiple edges’ are given by\n\nrsm_1$M\n\n             M1    M2\nExpected  2.273 3.727\nVariance  0.986 0.986\nUpper 95% 4.259 5.713\nLower 95% 0.287 1.741\n\n\nwhich are calculated using the numerically found probability distributions under RSM (no analytical solutions exist for these moments).\nUnder the IEA models (IEAS or ISA), moments of these statistics, together with the complexity statistic \\(R_k\\) representing the sequence of frequencies of edge sites with multiplicities 0,1,…,k, are found using derived formulas. Thus, there is no limit on multigraph size to use these. When the IEAS model is used to approximate the RSM model as shown above:\n\nieas_1$M\n\n              M1    M2\nObserved   3.000 3.000\nExpected   2.273 3.727\nVariance   1.412 1.412\nUpper 95%  4.649 6.104\nLower 95% -0.104 1.351\n\nieas_1$R\n\n             R0     R1     R2\nObserved  2.000  2.000  2.000\nExpected  2.674  1.588  1.030\nVariance  0.575  1.129  0.760\nUpper 95% 4.191  3.713  2.773\nLower 95% 1.156 -0.537 -0.713\n\n\nWhen the ISA model is used to approximate the RSM model (see above):\n\nisa_1 &lt;-   iea_model(adj = A , type = 'graph',  \n                     model = 'ISA', K = 0, apx = TRUE)\nisa_1$M\n\n             M1    M2\nObserved  3.000 3.000\nExpected  2.583 3.417\nVariance  1.471 1.471\nUpper 95% 5.009 5.842\nLower 95% 0.158 0.991\n\nisa_1$R\n\n             R0     R1     R2\nObserved  2.000  2.000  2.000\nExpected  2.599  1.703  1.018\nVariance  0.622  1.223  0.748\nUpper 95% 4.176  3.915  2.748\nLower 95% 1.021 -0.509 -0.711\n\n\nThe IEA models can also be used independent of the RSM model. For example, the IEAS model can be used where edge assignment probabilities are estimated using the observed edge multiplicities (maximum likelihood estimates):\n\nieas_2 &lt;-   iea_model(adj = A , type = 'graph',  \n                      model = 'IEAS', K = 0, apx = FALSE)\nieas_2$M\n\n             M1    M2\nObserved  3.000 3.000\nExpected  3.000 3.000\nVariance  1.500 1.500\nUpper 95% 5.449 5.449\nLower 95% 0.551 0.551\n\nieas_2$R\n\n             R0     R1     R2\nObserved  2.000  2.000  2.000\nExpected  2.845  1.331  1.060\nVariance  0.434  0.805  0.800\nUpper 95% 4.163  3.125  2.849\nLower 95% 1.528 -0.464 -0.729\n\n\nThe ISA model can also be used independent of the RSM model. Then, a sequence containing the stub assignment probabilities (for example based on prior belief) should be given as argument:\n\nisa_2 &lt;-   iea_model(adj = A , type = 'graph',  \n                     model = 'ISA', K = 0, apx = FALSE, p.seq = c(1/3, 1/3, 1/3))\nisa_2$M\n\n              M1    M2\nObserved   3.000 3.000\nExpected   2.000 4.000\nVariance   1.333 1.333\nUpper 95%  4.309 6.309\nLower 95% -0.309 1.691\n\nisa_2$R\n\n             R0     R1     R2\nObserved  2.000  2.000  2.000\nExpected  2.144  2.248  1.160\nVariance  0.632  1.487  0.710\nUpper 95% 3.734  4.687  2.845\nLower 95% 0.554 -0.190 -0.525\n\n\nThe interval estimates can then be visualized to detect discrepancies between observed and expected values thus indicating social mechanisms at play in the generation of edges, and to detect interval overlap and potential interdependence between different types of edges (see Shafie 2015,2016; Shafie & Schoch 2021)."
  },
  {
    "objectID": "project/rmm/index.html#goodness-of-fit-tests",
    "href": "project/rmm/index.html#goodness-of-fit-tests",
    "title": "Multigraph Representation of Network Data",
    "section": "Goodness of fit tests",
    "text": "Goodness of fit tests\nGoodness of fits tests of multigraph models using Pearson (S) and information divergence (A) test statistics under the random stub matching (RSM) and by independent edge assignments (IEA) model, where the latter is either independent edge assignments of stubs (IEAS) or independent stub assignment (ISA). The tests are performed using goodness-of-fit measures between the edge multiplicity sequence of a specified model or an observed multigraph, and the expected multiplicity sequence according to a simple or composite hypothesis."
  },
  {
    "objectID": "project/rmm/index.html#simulated-goodness-of-fit-tests",
    "href": "project/rmm/index.html#simulated-goodness-of-fit-tests",
    "title": "Multigraph Representation of Network Data",
    "section": "Simulated goodness of fit tests",
    "text": "Simulated goodness of fit tests\nProbability distributions of test statistics, summary of tests, moments of tests statistics, adjusted test statistics, critical values, significance level according to asymptotic distribution, and power of tests can be examined using gof_sim given a specified model from which we simulate observed values from, and a null or non-null hypothesis from which we calculate expected values from. This in order to investigate the behavior of the null and non-null distributions of the test statistics and their fit to to asymptotic chi-square distributions.\n\nExample\nSimulated goodness of fit tests for multigraphs with n=4 nodes and m=10 edges.\n(1) Testing a simple IEAS hypothesis with degree sequence (6,6,6,2) against a RSM model with degrees (8,8,2,2):\n\ngof1 &lt;- gof_sim(m = 10, model = 'IEAS', deg.mod = c(8,8,2,2), \n                hyp = 'IEAS', deg.hyp = c(6,6,6,2))\n\n(2) Testing a correctly specified simple IEAS hypothesis with degree sequence (14,2,2,2):\n\ngof2 &lt;- gof_sim(m = 10, model = 'IEAS', deg.mod = c(14,2,2,2), \n                hyp = 'IEAS', deg.hyp = c(14,2,2,2))\n\nThe non-null (gof1) and null (gof2) distributions of the test statistics together with their asymptotic chi2-distribution can be visualized using ggplot2:\n \n(3) Testing a composite IEAS hypothesis against a RSM model with degree sequence (14,2,2,2):\n\ngof3 &lt;- gof_sim(m = 10, model = 'RSM', deg.mod = c(14,2,2,2), \n                hyp = 'IEAS', deg.hyp = 0)\n\n(4) Testing a composite ISA hypothesis against a ISA model with degree sequence (14,2,2,2):\n\ngof4 &lt;- gof_sim(m = 10, model = 'ISA', deg.mod = c(14,2,2,2), \n                hyp = 'ISA', deg.hyp = 0)\n\nThe non-null (gof3) and null (gof4) distributions of the test statistics can then be visualized as shown above to check their fit to the asymptotic χ²-distribution."
  },
  {
    "objectID": "project/rmm/index.html#performing-the-goodness-of-fit-test-on-your-data",
    "href": "project/rmm/index.html#performing-the-goodness-of-fit-test-on-your-data",
    "title": "Multigraph Representation of Network Data",
    "section": "Performing the goodness of fit test on your data",
    "text": "Performing the goodness of fit test on your data\nUse function gof_test to test whether the observed data follows IEA approximations of the RSM model. The null hypotheses can be simple or composite, although the latter is not recommended for small multigraphs as it is difficult to detect a false composite hypothesis under an RSM model and under IEA models (this can be checked and verified using gof_sim to simulate these cases).\nNon-rejection of the null implies that the approximations fit the data, thus implying that above statistics under the IEA models can be used to further analyze the observed network. Consider the following multigraph from the well known Florentine family network with marital. This multigraphs is aggregated based on the three actor attributes wealth (W), number of priorates (P) and total number of ties (T) which are all dichotomized to reflect high or low economic, political and social influence (details on the aggregation can be found in Shafie, 2015):\n\nThe multiplicity sequence represented as an upper triangular matrix for this mutigrpah is given by\n\nflor_m &lt;- t(matrix(c (0, 0, 1, 0, 0, 0, 0, 0,\n                      0, 0, 0, 0, 0, 0, 0, 0,\n                      0, 0, 0, 2, 0, 0, 1, 5,\n                      0, 0, 0, 0, 0, 0, 1, 1,\n                      0, 0, 0, 0, 0, 0, 1, 2,\n                      0, 0, 0, 0, 0, 0, 2, 1,\n                      0, 0, 0, 0, 0, 0, 0, 2,\n                      0, 0, 0, 0, 0, 0, 0, 1), nrow= 8, ncol=8))\n\nThe equivalence of adjacency matrix for the multigraph is given by\n\nflor_adj &lt;- flor_m+t(flor_m)\nflor_adj \n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    1    0    0    0    0    0\n[2,]    0    0    0    0    0    0    0    0\n[3,]    1    0    0    2    0    0    1    5\n[4,]    0    0    2    0    0    0    1    1\n[5,]    0    0    0    0    0    0    1    2\n[6,]    0    0    0    0    0    0    2    1\n[7,]    0    0    1    1    1    2    0    2\n[8,]    0    0    5    1    2    1    2    2\n\n\nwith the diagonal representing the loops double counted (Shafie, 2016). The function get_degree_seq can now be used to find the degree sequence for this multigraph:\n\nflor_d &lt;- get_degree_seq(adj = flor_adj, type = 'multigraph')\nflor_d\n\n[1]  1  0  9  4  3  3  7 13\n\n\nNow we test whether the observed network fits the IEAS or the ISA model. The \\(p\\)-values for testing whether there is a significant difference between observed and expected edge multiplicity values according to the two approximate IEA models are given in the output tables below. Note that the asymptotic χ²-distribution has \\(r-1 = (n(n+1)/2) - 1 =35\\) degrees of freedom.\n\nflor_ieas_test &lt;- gof_test(flor_adj, 'multigraph', 'IEAS', flor_d, 35)\nflor_ieas_test\n\n  Stat dof Stat(obs) p-value\n1    S  35    15.762   0.998\n2    A  35    18.905   0.988\n\n\n\nflor_isa_test &lt;- gof_test(flor_adj, 'multigraph', 'ISA', flor_d, 35)\nflor_isa_test \n\n  Stat dof Stat(obs) p-value\n1    S  35    16.572   0.997\n2    A  35    19.648   0.983\n\n\nThe results show that we have strong evidence for the null such that we fail to reject it. Thus, there is not a significant difference between the observed and the expected edge multiplicity sequence according on the two IEA models. Statistics derived under these models presented above can thus be used to analyze the structure of these multigraphs."
  },
  {
    "objectID": "project/rmm/index.html#references",
    "href": "project/rmm/index.html#references",
    "title": "Multigraph Representation of Network Data",
    "section": "References",
    "text": "References\n\nShafie, T. (2015). A multigraph approach to social network analysis. Journal of Social Structure, 16. Link\nShafie, T. (2016). Analyzing local and global properties of multigraphs. The Journal of Mathematical Sociology, 40(4), 239-264. Link\nFrank, O., Shafie, T., (2018). Random Multigraphs and Aggregated Triads with Fixed Degrees. Network Science, 6(2), 232-250. Link\nShafie, T., Schoch, D. (2021) Multiplexity analysis of networks using multigraph representations. Statistical Methods & Applications 30, 1425–1444. Link\nShafie, T. (2022). Goodness of fit tests for random multigraph models, Journal of Applied Statistics. Link"
  },
  {
    "objectID": "project/nexus/index.html",
    "href": "project/nexus/index.html",
    "title": "NEXUS1492 - Reconstructing Archaeological Networks",
    "section": "",
    "text": "Between 2013-2018, I worked in international ERC-Synergy research project NEXUS1492 investigates the impacts of colonial encounters in the Caribbean through the reconstruction and modelling of archaeological networks.\nYou can read more about the project and its output here."
  },
  {
    "objectID": "project/nexus/index.html#project-summary",
    "href": "project/nexus/index.html#project-summary",
    "title": "NEXUS1492 - Reconstructing Archaeological Networks",
    "section": "",
    "text": "Between 2013-2018, I worked in international ERC-Synergy research project NEXUS1492 investigates the impacts of colonial encounters in the Caribbean through the reconstruction and modelling of archaeological networks.\nYou can read more about the project and its output here."
  },
  {
    "objectID": "project/nexus/index.html#references",
    "href": "project/nexus/index.html#references",
    "title": "NEXUS1492 - Reconstructing Archaeological Networks",
    "section": "References",
    "text": "References\n\nShafie T., Schoch D., Mans J., Hofman C., Brandes U., (2017). Hypergraph Representations: A Study of Carib Attacks on Colonial Forces, 1509-1700. Journal of Historical Network Research,1(1), 52-70. Link\nLaffoon, J.E., Sonnemann, T.F., Shafie, T., Hofman, C.L., Brandes, U. and Davies, G.R., (2017). Investigating human geographic origins using dual-isotope (87Sr/86Sr, δ18O) assignment approaches. PloS one, 12(2), p.e0172562. Link\nAmati, V., Shafie, T., Brandes U., (2018) Reconstructing Archaeological Networks with Structural Holes. Journal of Archaeological Method and Theory volume 25, 226–253. Link\nAmati, V., Mol, A., Shafie, T., Hofman, C., Brandes U., (2020). A Framework for Reconstructing Archaeological Networks Using Exponential Random Graph Models. Journal of Archaeological Method and Theory volume 27, 192–219. Link"
  },
  {
    "objectID": "teaching/Tidyverse/material/bechdel.html",
    "href": "teaching/Tidyverse/material/bechdel.html",
    "title": "Bechdel",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”. We will together fill in the blanks denoted by ___."
  },
  {
    "objectID": "teaching/Tidyverse/material/bechdel.html#data-and-packages",
    "href": "teaching/Tidyverse/material/bechdel.html#data-and-packages",
    "title": "Bechdel",
    "section": "Data and packages",
    "text": "Data and packages\nWe start with loading the packages we’ll use.\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\n\nThe dataset contains information on 1794 movies released between 1970 and 2013. However we’ll focus our analysis on movies released between 1990 and 2013.\n\nbechdel90_13 &lt;- bechdel %&gt;% \n  filter(between(year, 1990, 2013))\n\nThere are ___ such movies.\nThe financial variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars\ndomgross_2013: Domestic gross (US) in 2013 inflation adjusted dollars\nintgross_2013: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars\n\nAnd we’ll also use the binary and clean_test variables for grouping."
  },
  {
    "objectID": "teaching/Tidyverse/material/bechdel.html#analysis",
    "href": "teaching/Tidyverse/material/bechdel.html#analysis",
    "title": "Bechdel",
    "section": "Analysis",
    "text": "Analysis\nLet’s take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the binary variable.\n\nbechdel90_13 %&gt;%\n  group_by(binary) %&gt;%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 2 × 4\n  binary med_budget med_domgross med_intgross\n  &lt;chr&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 FAIL    48385984.    57318606.    104475669\n2 PASS    31070724     45330446.     80124349\n\n\nNext, let’s take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result. This information is stored in the clean_test variable, which takes on the following values:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\n\nbechdel90_13 %&gt;%\n  #group_by(___) %&gt;%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 1 × 3\n  med_budget med_domgross med_intgross\n       &lt;int&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1   37878971     52270207     93523336\n\n\nIn order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we’ll first create a new variable called roi as the ratio of the gross to budget.\n\nbechdel90_13 &lt;- bechdel90_13 %&gt;%\n  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)\n\nLet’s see which movies have the highest return on investment.\n\nbechdel90_13 %&gt;%\n  arrange(desc(roi)) %&gt;% \n  select(title, roi, year)\n\n# A tibble: 1,615 × 3\n   title                     roi  year\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;int&gt;\n 1 Paranormal Activity      671.  2007\n 2 The Blair Witch Project  648.  1999\n 3 El Mariachi              583.  1992\n 4 Clerks.                  258.  1994\n 5 In the Company of Men    231.  1997\n 6 Napoleon Dynamite        227.  2004\n 7 Once                     190.  2006\n 8 The Devil Inside         155.  2012\n 9 Primer                   142.  2004\n10 Fireproof                134.  2008\n# ℹ 1,605 more rows\n\n\nBelow is a visualization of the return on investment by test result, however it’s difficult to see the distributions due to a few extreme observations.\n\nggplot(data = bechdel90_13, \n       mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"___\",\n    color = \"Binary Bechdel result\"\n    )\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel90_13 %&gt;%\n  filter(roi &gt; 400) %&gt;%\n  select(title, budget_2013, domgross_2013, year)\n\n# A tibble: 3 × 4\n  title                   budget_2013 domgross_2013  year\n  &lt;chr&gt;                         &lt;int&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Paranormal Activity          505595     121251476  2007\n2 The Blair Witch Project      839077     196538593  1999\n3 El Mariachi                   11622       3388636  1992\n\n\nZooming in on the movies with roi &lt; ___ provides a better view of how the medians across the categories compare:\n\nggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    subtitle = \"___\", # Something about zooming in to a certain level\n    x = \"Detailed Bechdel result\",\n    y = \"Return on investment\",\n    color = \"Binary Bechdel result\"\n    ) +\n  coord_cartesian(ylim = c(0, 15))"
  },
  {
    "objectID": "teaching/Tidyverse/material/legos.html",
    "href": "teaching/Tidyverse/material/legos.html",
    "title": "Legos",
    "section": "",
    "text": "Here, we work with (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US."
  },
  {
    "objectID": "teaching/Tidyverse/material/legos.html#data-and-packages",
    "href": "teaching/Tidyverse/material/legos.html#data-and-packages",
    "title": "Legos",
    "section": "Data and Packages",
    "text": "Data and Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data is given to import.\n\nlibrary(tidyverse)\n\nThe following variables are available in the data set:\n\nfirst_name: First name of customer\nlast_name: Last name of customer\nage: Age of customer\nphone_number: Phone number of customer\nset_id: Set ID of lego set purchased\nnumber: Item number of lego set purchased\ntheme: Theme of lego set purchased\nsubtheme: Sub theme of lego set purchased\nyear: Year of purchase\nname: Name of lego set purchased\npieces: Number of pieces of legos in set purchased\nus_price: Price of set purchase in US Dollars\nimage_url: Image URL of lego set purchased\nquantity: Quantity of lego set(s) purchased"
  },
  {
    "objectID": "teaching/Tidyverse/material/plastic-waste.html",
    "href": "teaching/Tidyverse/material/plastic-waste.html",
    "title": "Global plastic waste",
    "section": "",
    "text": "Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010.\nAdditionally, National Geographic ran a data visualization communication contest on plastic waste as seen here."
  },
  {
    "objectID": "teaching/Tidyverse/material/plastic-waste.html#packages",
    "href": "teaching/Tidyverse/material/plastic-waste.html#packages",
    "title": "Global plastic waste",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "teaching/Tidyverse/material/plastic-waste.html#data",
    "href": "teaching/Tidyverse/material/plastic-waste.html#data",
    "title": "Global plastic waste",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file. You can read it in using the following (make sure you save the data in your working directory).\n\nplastic_waste &lt;- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html",
    "href": "teaching/Tidyverse/material/nobel-laureates.html",
    "title": "Nobel Laureates",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science. You can read the article here. In the article they show that while most living Nobel laureates in the sciences are based in the US, many of them were born in other countries. This is one reason why scientific leaders say that immigration is vital for progress. In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions."
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#packages",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#packages",
    "title": "Nobel Laureates",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#data",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#data",
    "title": "Nobel Laureates",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSV (comma separated values) file. You can read it in using the following.\n\nnobel &lt;- read_csv(\"data/nobel.csv\")\n\nThe variable descriptions are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#get-to-know-your-data",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#get-to-know-your-data",
    "title": "Nobel Laureates",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code."
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Nobel Laureates",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\nNote: we can achieve the same result using the fct_other() function we’ve seen before (i.e. with country_us = fct_other(country, \"USA\")). We decided to use the if_else() here to show you one example of an if statement in R.\n\nnobel_living &lt;- nobel_living %&gt;%\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science &lt;- nobel_living %&gt;%\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the next exercise work with the nobel_living_science data frame you created above.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical."
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Nobel Laureates",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\nHint: You should be able to cheat borrow from code you used earlier to create the country_us variable.\n\nCreate a new variable called born_country_us that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Based on your visualization, do the data appear to support Buzzfeed’s claim? Explain your reasoning in 1-2 sentences.\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be a bar for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not."
  },
  {
    "objectID": "teaching/Tidyverse/material/nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "href": "teaching/Tidyverse/material/nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "title": "Nobel Laureates",
    "section": "Here’s where those immigrant Nobelists were born",
    "text": "Here’s where those immigrant Nobelists were born\nNote: your bar plot won’t exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.\n\nIn a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?"
  }
]